import gspread
import yfinance as yf
import pandas as pd
import numpy as np
import re
import time
import os
import sys
from datetime import datetime, timedelta
from google.oauth2.service_account import Credentials
from gspread.exceptions import WorksheetNotFound

# ============================
# âš™ï¸ è¨­å®šå€
# ============================
SHEET_NAME = "å°è‚¡æ³¨æ„è‚¡è³‡æ–™åº«_V33"
SOURCE_WORKSHEET = "è™•ç½®è‚¡90æ—¥æ˜ç´°"
DEST_WORKSHEET = "è™•ç½®è‚¡å‡ºé—œè¨˜éŒ„"

SERVICE_KEY_FILE = "service_key.json"

# ============================
# ğŸ› ï¸ å·¥å…·å‡½å¼
# ============================
def connect_google_sheets(sheet_name):
    """é€£ç·š Google Sheets"""
    try:
        scope = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        creds = Credentials.from_service_account_file(SERVICE_KEY_FILE, scopes=scope)
        gc = gspread.authorize(creds)
        sh = gc.open(sheet_name)
        return sh
    except Exception as e:
        print(f"âŒ Google Sheet é€£ç·šå¤±æ•— ({sheet_name}): {e}")
        return None

def parse_roc_date(date_str):
    """è§£ææ°‘åœ‹æˆ–è¥¿å…ƒæ—¥æœŸ"""
    s = str(date_str).strip()
    match = re.match(r'^(\d{2,3})[/-](\d{1,2})[/-](\d{1,2})$', s)
    if match:
        y, m, d = map(int, match.groups())
        y_final = y + 1911 if y < 1911 else y
        return datetime(y_final, m, d)
    for fmt in ["%Y/%m/%d", "%Y-%m-%d", "%Y%m%d"]:
        try: return datetime.strptime(s, fmt)
        except: continue
    return None

def determine_status(pre_pct, in_pct):
    """
    åˆ¤æ–·è™•ç½®ç‹€æ…‹ (å›æ­¸åŸå§‹æ¨™æº–)
    é–€æª»ï¼š5% / 15%
    """
    if in_pct > 15: return "ğŸ‘‘ å¦–è‚¡èª•ç”Ÿ"
    elif in_pct > 5: return "ğŸ”¥ å¼·å‹¢çªåœ"
    elif in_pct < -15: return "ğŸ’€ äººå»æ¨“ç©º"
    elif in_pct < -5: return "ğŸ“‰ èµ°å‹¢ç–²è»Ÿ"
    else: return "ğŸ§Š å¤šç©ºè† è‘—"

def get_ticker_list(code, market=""):
    """æ ¹æ“šå¸‚å ´åˆ¥èˆ‡è‚¡è™Ÿæ±ºå®šå˜—è©¦çš„é †åºï¼Œæ¸›å°‘ 404 éŒ¯èª¤"""
    code = str(code)
    if "ä¸Šæ«ƒ" in market or "TPEx" in market:
        return [f"{code}.TWO", f"{code}.TW"]
    if "ä¸Šå¸‚" in market:
        return [f"{code}.TW", f"{code}.TWO"]
    if code and code[0] in ['3', '4', '5', '6', '8']:
        return [f"{code}.TWO", f"{code}.TW"]
    return [f"{code}.TW", f"{code}.TWO"]

def fetch_stock_data(code, start_date, jail_end_date, market=""):
    """æŠ“å–æ­·å²è‚¡åƒ¹ä¸¦è¨ˆç®—ç‹€æ…‹èˆ‡å‡ºé—œå¾Œèµ°å‹¢ (æ“´å……è‡³ D+20)"""
    try:
        # æŠ“å–ç¯„åœæ“´å¤§ï¼Œç¢ºä¿æœ‰è¶³å¤ çš„äº¤æ˜“æ—¥è¨ˆç®—åˆ° D+20
        fetch_start = start_date - timedelta(days=60)
        fetch_end = jail_end_date + timedelta(days=60) 
        
        tickers_to_try = get_ticker_list(code, market)
        df = pd.DataFrame()
        
        for ticker in tickers_to_try:
            try:
                temp_df = yf.Ticker(ticker).history(start=fetch_start, end=fetch_end, auto_adjust=True)
                if not temp_df.empty:
                    df = temp_df
                    break
            except Exception:
                continue
        
        if df.empty:
            return None

        df.index = df.index.tz_localize(None)
        df = df.ffill()

        # === 1. è¨ˆç®—è™•ç½®ç‹€æ…‹ ===
        mask_jail = (df.index >= pd.Timestamp(start_date)) & (df.index <= pd.Timestamp(jail_end_date))
        df_jail = df[mask_jail]
        mask_before = df.index < pd.Timestamp(start_date)
        
        pre_pct = 0.0
        in_pct = 0.0
        
        if mask_before.any():
            jail_base_p = df[mask_before]['Close'].iloc[-1]
            target_idx = max(0, len(df[mask_before]) - len(df_jail))
            pre_entry = df[mask_before]['Open'].iloc[target_idx] if len(df[mask_before]) > target_idx else jail_base_p
            if pre_entry != 0:
                pre_pct = ((jail_base_p - pre_entry) / pre_entry) * 100

        jail_end_price = 0
        if not df_jail.empty:
            jail_start_price = df_jail['Open'].iloc[0]
            jail_end_price = df_jail['Close'].iloc[-1]
            if jail_start_price != 0:
                in_pct = ((jail_end_price - jail_start_price) / jail_start_price) * 100
        
        status = determine_status(pre_pct, in_pct)

        # === 2. è¨ˆç®—å‡ºé—œå¾Œ D+1 ~ D+20 ===
        df_after = df[df.index > pd.Timestamp(jail_end_date)]
        
        if not df_after.empty:
            release_date_str = df_after.index[0].strftime("%Y/%m/%d")
        else:
            release_date_str = (jail_end_date + timedelta(days=1)).strftime("%Y/%m/%d")

        post_data = []
        accumulated_pct = 0.0
        base_price = jail_end_price if jail_end_price != 0 else (df_after['Open'].iloc[0] if not df_after.empty else 0)

        track_days = 20
        for i in range(track_days):
            if i < len(df_after):
                curr_close = df_after['Close'].iloc[i]
                prev_close = df_after['Close'].iloc[i-1] if i > 0 else base_price
                if prev_close != 0:
                    daily_chg = ((curr_close - prev_close) / prev_close) * 100
                    post_data.append(f"{daily_chg:+.1f}%")
                else:
                    post_data.append("0.0%")
                
                # è¨ˆç®—ç´¯ç©æ¼²å¹… (D+20 æˆ–æœ€å¾Œä¸€å¤©)
                if i == len(df_after) - 1 or i == track_days - 1:
                    if base_price != 0:
                        accumulated_pct = ((curr_close - base_price) / base_price) * 100
            else:
                post_data.append("")

        while len(post_data) < track_days:
            post_data.append("")

        return {
            "status": status,
            "pre_pct": f"{pre_pct:+.1f}%",
            "in_pct": f"{in_pct:+.1f}%",
            "acc_pct": f"{accumulated_pct:+.1f}%",
            "daily_trends": post_data,
            "release_date": release_date_str
        }

    except Exception as e:
        print(f"âš ï¸ æ•¸æ“šè¨ˆç®—éŒ¯èª¤ {code}: {e}")
        return None

# ============================
# ğŸš€ ä¸»ç¨‹å¼
# ============================
def main():
    print("ğŸš€ é–‹å§‹åŸ·è¡Œè™•ç½®è‚¡å‡ºé—œè¨˜éŒ„æ›´æ–° (D+20ç‰ˆ)...")
    
    sh = connect_google_sheets(SHEET_NAME)
    if not sh: return

    try:
        ws_source = sh.worksheet(SOURCE_WORKSHEET)
    except WorksheetNotFound:
        print(f"âŒ æ‰¾ä¸åˆ°ä¾†æºå·¥ä½œè¡¨ '{SOURCE_WORKSHEET}'")
        return

    # æ“´å…… Header è‡³ D+20
    header_base = ["å‡ºé—œæ—¥æœŸ", "è‚¡è™Ÿ", "è‚¡å", "ç‹€æ…‹", "è™•ç½®å‰%", "è™•ç½®ä¸­%", "ç´¯ç©æ¼²è·Œå¹…"]
    header_days = [f"D+{i+1}" for i in range(20)]
    header = header_base + header_days
    
    try:
        ws_dest = sh.worksheet(DEST_WORKSHEET)
    except WorksheetNotFound:
        print(f"ğŸ’¡ å·¥ä½œè¡¨ '{DEST_WORKSHEET}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨å»ºç«‹...")
        ws_dest = sh.add_worksheet(title=DEST_WORKSHEET, rows=1000, cols=60) 
        ws_dest.append_row(header)

    # è®€å–ç¾æœ‰è¨˜éŒ„
    raw_rows = ws_dest.get_all_values()
    existing_map = {} 
    
    if len(raw_rows) > 1:
        for row in raw_rows[1:]:
            if len(row) < 7: continue 
            rdate = str(row[0])
            rid = str(row[1])
            
            d_last_idx = 6 + 20 
            d_last = ""
            if len(row) > d_last_idx:
                d_last = str(row[d_last_idx]).strip()
            
            if rid:
                key = f"{rid}_{rdate}"
                row_dict = {}
                for idx, h in enumerate(header):
                    if idx < len(row):
                        row_dict[h] = row[idx]
                    else:
                        row_dict[h] = ""
                
                existing_map[key] = {
                    'data': row_dict,
                    'done': bool(d_last)
                }

    source_data = ws_source.get_all_records()
    processed_list = []
    
    status_order = ["ğŸ‘‘ å¦–è‚¡èª•ç”Ÿ", "ğŸ”¥ å¼·å‹¢çªåœ", "ğŸ§Š å¤šç©ºè† è‘—", "ğŸ“‰ èµ°å‹¢ç–²è»Ÿ", "ğŸ’€ äººå»æ¨“ç©º"]
    track_days = 20
    
    # çµ±è¨ˆå®¹å™¨
    daily_stats = {s: [{'sum': 0.0, 'wins': 0, 'count': 0} for _ in range(track_days)] for s in status_order}
    summary_stats = {s: {'count': 0, 'wins': 0, 'total_pct': 0.0} for s in status_order}
    
    # === æ–°å¢ï¼šæ¯5æ—¥å€é–“çµ±è¨ˆå®¹å™¨ ===
    # ç”¨ä¾†å­˜å„²ç´¯ç©åˆ° D+5, D+10, D+15, D+20 çš„æ‰€æœ‰æ¨£æœ¬æ•¸æ“š
    interval_checkpoints = [5, 10, 15, 20]
    interval_data = {s: {cp: [] for cp in interval_checkpoints} for s in status_order}

    today = datetime.now()
    print(f"ğŸ” æƒæ {len(source_data)} ç­†è™•ç½®ç´€éŒ„...")
    total_count = 0
    update_count = 0

    for row in source_data:
        code = str(row.get('ä»£è™Ÿ', '')).replace("'", "").strip()
        name = row.get('åç¨±', '')
        period = str(row.get('è™•ç½®æœŸé–“', '')).strip()
        market = str(row.get('å¸‚å ´', ''))
        
        if not code or not period: continue
        
        dates = re.split(r'[~-ï½]', period)
        if len(dates) < 2: continue
        
        s_date = parse_roc_date(dates[0])
        e_date = parse_roc_date(dates[1])
        
        if not s_date or not e_date: continue
        if e_date > today: continue 

        result = fetch_stock_data(code, s_date, e_date, market)
        
        if not result:
            continue
            
        release_date_str = result['release_date']
        key = f"{code}_{release_date_str}"
        
        row_vals = []
        if key in existing_map and existing_map[key]['done']:
            old_row = existing_map[key]['data']
            row_vals = [old_row.get(h, "") for h in header]
        else:
            row_vals = [
                release_date_str, code, name, result['status'],
                result['pre_pct'], result['in_pct'], result['acc_pct']
            ] + result['daily_trends']
            update_count += 1
            print(f"  âœ¨ æ›´æ–°: {code} {name} | {result['status']}")
            time.sleep(0.5)
        
        processed_list.append(row_vals)

        # --- çµ±è¨ˆé‚è¼¯ ---
        stat_status = row_vals[3] 
        
        # 1. ç´¯ç©æ¼²å¹… (D+20) & 2. æ¯æ—¥è©³ç´° (D+1 ~ D+20)
        acc_pct_str = row_vals[6]
        if stat_status in summary_stats:
            summary_stats[stat_status]['count'] += 1
            try:
                acc_val = float(acc_pct_str.replace('%', '').replace('+', ''))
                summary_stats[stat_status]['total_pct'] += acc_val
                if acc_val > 0: summary_stats[stat_status]['wins'] += 1
            except: pass
            
        if stat_status in daily_stats:
            # ç‚ºäº†è¨ˆç®—å€é–“ç´¯ç©ï¼Œæˆ‘å€‘éœ€è¦è¿½è¹¤é€™æ”¯è‚¡ç¥¨çš„ã€Œç´¯ç©è¤‡åˆ©ã€
            # æˆ‘å€‘å¾ row_vals è®€å– D+1 ~ D+20 çš„æ¯æ—¥ %ï¼Œç„¶å¾Œè¨ˆç®—ç´¯ç©
            
            current_compound = 1.0 # åˆå§‹æœ¬é‡‘
            
            for day_idx in range(track_days):
                col_idx = 7 + day_idx
                if col_idx < len(row_vals):
                    val_str = row_vals[col_idx]
                    if val_str:
                        try:
                            # æ¯æ—¥æ¼²è·Œ %
                            daily_val = float(val_str.replace('%', '').replace('+', ''))
                            
                            # 1. æ›´æ–°æ¯æ—¥å¹³å‡èˆ‡å‹ç‡çµ±è¨ˆ
                            daily_stats[stat_status][day_idx]['count'] += 1
                            daily_stats[stat_status][day_idx]['sum'] += daily_val
                            if daily_val > 0:
                                daily_stats[stat_status][day_idx]['wins'] += 1
                                
                            # 2. è¨ˆç®—è¤‡åˆ©ç´¯ç©
                            # å…¬å¼: (1 + r1) * (1 + r2) ...
                            current_compound *= (1 + daily_val / 100)
                            
                            # 3. æª¢æŸ¥æ˜¯å¦ç‚º 5, 10, 15, 20 çš„ç¯€é»
                            current_day = day_idx + 1
                            if current_day in interval_checkpoints:
                                # ç´¯ç©å ±é…¬ç‡ %
                                cumulative_return = (current_compound - 1) * 100
                                interval_data[stat_status][current_day].append(cumulative_return)
                                
                        except: pass
        
        total_count += 1

    # 4. æ’åº
    processed_list.sort(key=lambda x: x[0], reverse=True)
    
    # 5. === å»ºæ§‹å³å´çµ±è¨ˆå€ (åŒ…å«æ¯5æ—¥çµ±è¨ˆ) ===
    print("ğŸ“Š è¨ˆç®— D+20 èˆ‡ å€é–“çµ±è¨ˆæ•¸æ“š...")
    
    right_side_rows = []
    
    # --- è¡¨æ ¼ 1: ç¸½è¦½ ---
    right_side_rows.append(["", "ğŸ“Š ç‹€æ…‹ç¸½è¦½ (åŸå§‹æ¨™æº–5%/15%)", "å€‹è‚¡æ•¸", "D+20å‹ç‡", "D+20å¹³å‡", "", "", "", ""])
    for s in status_order:
        t = summary_stats[s]['count']
        w = summary_stats[s]['wins']
        avg = summary_stats[s]['total_pct'] / t if t > 0 else 0
        wr = (w / t * 100) if t > 0 else 0
        right_side_rows.append(["", s, t, f"{wr:.1f}%", f"{avg:+.1f}%", "", "", "", ""])

    right_side_rows.append([""] * 9) 

    days_header = [f"D+{i+1}" for i in range(track_days)]

    # --- è¡¨æ ¼ 2: æ¯æ—¥å¹³å‡ ---
    right_side_rows.append(["", "ğŸ“ˆ å¹³å‡æ¼²è·Œå¹… (æ¯æ—¥)"] + days_header)
    for s in status_order:
        row_vals = ["", s]
        for d in range(track_days):
            data = daily_stats[s][d]
            if data['count'] > 0:
                avg = data['sum'] / data['count']
                row_vals.append(f"{avg:+.1f}%")
            else:
                row_vals.append("-")
        right_side_rows.append(row_vals)

    right_side_rows.append([""] * (2 + track_days)) 

    # --- è¡¨æ ¼ 3: æ¯æ—¥å‹ç‡ ---
    right_side_rows.append(["", "ğŸ† æ¯æ—¥å‹ç‡ (æ¯æ—¥)"] + days_header)
    for s in status_order:
        row_vals = ["", s]
        for d in range(track_days):
            data = daily_stats[s][d]
            if data['count'] > 0:
                wr = (data['wins'] / data['count']) * 100
                row_vals.append(f"{wr:.1f}%")
            else:
                row_vals.append("-")
        right_side_rows.append(row_vals)
        
    right_side_rows.append([""] * (2 + track_days)) 

    # --- è¡¨æ ¼ 4: æ¯5æ—¥ç´¯è¨ˆå‹ç‡ (æ–°å¢) ---
    interval_header = ["D+5", "D+10", "D+15", "D+20"]
    right_side_rows.append(["", "ğŸ† æ¯5æ—¥ç´¯è¨ˆå‹ç‡"] + interval_header)
    
    for s in status_order:
        row_vals = ["", s]
        for cp in interval_checkpoints:
            data_list = interval_data[s][cp]
            if data_list:
                wins = sum(1 for x in data_list if x > 0)
                total = len(data_list)
                wr = (wins / total * 100)
                row_vals.append(f"{wr:.1f}%")
            else:
                row_vals.append("-")
        right_side_rows.append(row_vals)

    right_side_rows.append([""] * (2 + 4))

    # --- è¡¨æ ¼ 5: æ¯5æ—¥ç´¯è¨ˆæ¼²è·Œ (æ–°å¢) ---
    right_side_rows.append(["", "ğŸ“ˆ æ¯5æ—¥ç´¯è¨ˆæ¼²è·Œ"] + interval_header)
    
    for s in status_order:
        row_vals = ["", s]
        for cp in interval_checkpoints:
            data_list = interval_data[s][cp]
            if data_list:
                avg = sum(data_list) / len(data_list)
                row_vals.append(f"{avg:+.1f}%")
            else:
                row_vals.append("-")
        right_side_rows.append(row_vals)


    # 6. === åˆä½µ ===
    # å·¦å´æœ‰ 27 æ¬„ (0~26)
    # æˆ‘å€‘è®“å³å´å¾ç¬¬ 29 æ¬„é–‹å§‹ (Index 28)ï¼Œç•™ Index 27 ç‚ºç©º
    final_header = header + [""] * (3 + track_days) # é ç•™å³å´ç©ºé–“
    final_output = [final_header]
    
    max_rows = max(len(processed_list), len(right_side_rows))
    
    for i in range(max_rows):
        if i < len(processed_list):
            left_part = processed_list[i]
        else:
            left_part = [""] * 27 
            
        if i < len(right_side_rows):
            right_part = right_side_rows[i]
        else:
            right_part = [""] * (3 + track_days)
        
        final_output.append(left_part + [""] + right_part)

    # å¯«å…¥ Sheet
    ws_dest.clear()
    ws_dest.update(final_output)

    # 7. === è¨­å®šæ¢ä»¶æ ¼å¼ ===
    print("ğŸ¨ æ›´æ–°æ¢ä»¶æ ¼å¼åŒ– (åŒ…å«æ–°è¡¨æ ¼)...")

    # å·¦å´ç¯„åœ: Col 4 (E) ~ Col 27 (AA)
    # å³å´ç¯„åœ: Col 29 (AC) ~ End
    ranges = [
        {"sheetId": ws_dest.id, "startRowIndex": 1, "startColumnIndex": 4, "endColumnIndex": 27},
        {"sheetId": ws_dest.id, "startRowIndex": 1, "startColumnIndex": 28, "endColumnIndex": 60}
    ]

    header_rule = {
        "addConditionalFormatRule": {
            "rule": {
                "ranges": ranges,
                "booleanRule": {
                    "condition": {"type": "TEXT_STARTS_WITH", "values": [{"userEnteredValue": "D+"}]},
                    "format": {
                        "backgroundColor": {"red": 1.0, "green": 0.9, "blue": 0.7}, 
                        "textFormat": {"bold": True}
                    }
                }
            },
            "index": 0 
        }
    }

    positive_rule = {
        "addConditionalFormatRule": {
            "rule": {
                "ranges": ranges,
                "booleanRule": {
                    "condition": {"type": "TEXT_CONTAINS", "values": [{"userEnteredValue": "+"}]},
                    "format": {"backgroundColor": {"red": 1.0, "green": 0.8, "blue": 0.8}}
                }
            },
            "index": 1
        }
    }

    negative_rule = {
        "addConditionalFormatRule": {
            "rule": {
                "ranges": ranges,
                "booleanRule": {
                    "condition": {"type": "TEXT_CONTAINS", "values": [{"userEnteredValue": "-"}]},
                    "format": {"backgroundColor": {"red": 0.8, "green": 1.0, "blue": 0.8}}
                }
            },
            "index": 2
        }
    }

    requests = [header_rule, positive_rule, negative_rule]

    # --- æ¨™è¨˜æœ€é«˜/æœ€ä½ (é‡å° D+1 ~ D+20 çš„æ¯æ—¥å‹ç‡) ---
    win_rate_start_row = -1
    for idx, row in enumerate(final_output):
        if len(row) > 28 and "ğŸ† æ¯æ—¥å‹ç‡ (æ¯æ—¥)" in str(row[29]):
            win_rate_start_row = idx
            break
    
    if win_rate_start_row != -1:
        start_col = 30
        end_col = 30 + track_days
        
        for col_idx in range(start_col, end_col): 
            col_values = []
            valid_rows = []
            for r in range(1, 6): 
                row_idx = win_rate_start_row + r
                if row_idx < len(final_output):
                    val_str = final_output[row_idx][col_idx]
                    try:
                        val = float(val_str.replace('%', ''))
                        col_values.append(val)
                        valid_rows.append(row_idx)
                    except:
                        col_values.append(-1.0) 
                        valid_rows.append(row_idx)
            
            valid_vals = [v for v in col_values if v != -1.0]
            if valid_vals:
                max_val = max(valid_vals)
                min_val = min(valid_vals)
                
                for i, val in enumerate(col_values):
                    if val == -1.0: continue
                    bg_color = None
                    if val == max_val:
                        bg_color = {"red": 1.0, "green": 0.8, "blue": 0.8} 
                    elif val == min_val:
                        bg_color = {"red": 0.8, "green": 1.0, "blue": 0.8} 
                    
                    if bg_color:
                        req = {
                            "repeatCell": {
                                "range": {
                                    "sheetId": ws_dest.id,
                                    "startRowIndex": valid_rows[i],
                                    "endRowIndex": valid_rows[i] + 1,
                                    "startColumnIndex": col_idx,
                                    "endColumnIndex": col_idx + 1
                                },
                                "cell": {"userEnteredFormat": {"backgroundColor": bg_color}},
                                "fields": "userEnteredFormat.backgroundColor"
                            }
                        }
                        requests.append(req)

    try:
        sh.batch_update({"requests": requests})
    except Exception as e:
        print(f"âš ï¸ æ ¼å¼åŒ–è¨­å®šå¤±æ•— (å¯èƒ½æ˜¯æ¬Šé™æˆ–ç‰ˆæœ¬å•é¡Œ): {e}")

    print(f"ğŸ‰ å®Œæˆï¼å…±æƒæ {total_count} ç­†ï¼Œæœ¬æ¬¡æ›´æ–° {update_count} ç­†ã€‚")

if __name__ == "__main__":
    main()
