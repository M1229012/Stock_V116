import gspread
import requests
import os
import json
import re
import time
import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from google.oauth2.service_account import Credentials
from gspread.exceptions import WorksheetNotFound
from io import StringIO

# === çˆ¬èŸ²ç›¸é—œå¥—ä»¶ ===
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# ============================
# âš™ï¸ è¨­å®šå€
# ============================
SHEET_NAME = "å°è‚¡æ³¨æ„è‚¡è³‡æ–™åº«_V33"
# ä¾†æºä¸é‡è¦äº†ï¼Œå› ç‚ºæˆ‘å€‘æœƒè‡ªå·±æŠ“ï¼Œä½†é‚„æ˜¯ç•™è‘—ç•¶å‚™æ¡ˆ
SOURCE_WORKSHEET = "è™•ç½®è‚¡90æ—¥æ˜ç´°" 
DEST_WORKSHEET = "ä¸€å¹´æœŸè™•ç½®å›æ¸¬æ•¸æ“š" 

SERVICE_KEY_FILE = "service_key.json"

# âš¡ æ³•äººåˆ¤æ–·é–¥å€¼
THRESH_FOREIGN = 0.010  # å¤–è³‡ 1.0%
THRESH_OTHERS  = 0.005  # æŠ•ä¿¡/è‡ªç‡Ÿ 0.5%

# ============================
# ğŸ› ï¸ çˆ¬èŸ²èˆ‡å·¥å…·å‡½å¼
# ============================
def get_driver():
    """åˆå§‹åŒ– Selenium Driver"""
    options = Options()
    options.add_argument('--headless=new')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def connect_google_sheets(sheet_name):
    """é€£ç·š Google Sheets"""
    try:
        scope = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        creds = Credentials.from_service_account_file(SERVICE_KEY_FILE, scopes=scope)
        gc = gspread.authorize(creds)
        sh = gc.open(sheet_name)
        return sh
    except Exception as e:
        print(f"âŒ Google Sheet é€£ç·šå¤±æ•— ({sheet_name}): {e}")
        return None

def is_valid_date_row(s): 
    return re.match(r"^\d{2,4}[/-]\d{1,2}[/-]\d{1,2}$", str(s).strip()) is not None

def roc_to_datestr(d_str):
    parts = re.split(r"[/-]", str(d_str).strip())
    if len(parts) < 2: return None
    y = int(parts[0])
    if y < 1911: y += 1911
    return f"{y:04d}-{int(parts[1]):02d}-{int(parts[2]):02d}"

# ============================
# ğŸ“… æ­·å²åå–®æŠ“å–é‚è¼¯ (é—œéµæ–°å¢)
# ============================
def fetch_historical_disposition_list_twse_tpex():
    """
    å¾è­‰äº¤æ‰€èˆ‡æ«ƒè²·ä¸­å¿ƒ Open Data æŠ“å–éå»ä¸€å¹´çš„è™•ç½®è‚¡
    é‚è¼¯ï¼šç›´æ¥æ‰“ API æˆ–æ˜¯æŠ“å– CSVï¼Œæ•´ç†å‡º (ä»£è™Ÿ, åç¨±, è™•ç½®èµ·æ—¥, è™•ç½®è¿„æ—¥)
    """
    print("ğŸŒ æ­£åœ¨é€£ç·šè­‰äº¤æ‰€/æ«ƒè²·ä¸­å¿ƒæŠ“å–ã€Œéå»365å¤©ã€æ­·å²è™•ç½®åå–®...")
    
    historical_data = []
    
    # è¨­å®šå›æ¸¬èµ·å§‹æ—¥ (ä»Šå¤©å¾€å‰æ¨ 365 å¤©)
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365)
    
    # è½‰æ›æˆæ°‘åœ‹å¹´å­—ä¸² (ä¾‹å¦‚ 113/01/01) ç”¨æ–¼æ¯”å° (å¦‚æœéœ€è¦)
    # ä½† Open Data API é€šå¸¸æ”¯æ´è¥¿å…ƒæˆ–ç‰¹å®šæ ¼å¼
    
    # 1. ä¸Šå¸‚ (TWSE) - è™•ç½®è­‰åˆ¸è³‡è¨Š
    # URL: https://www.twse.com.tw/rwd/zh/announced/punish?response=json
    # ç‚ºäº†ç¢ºä¿æŠ“åˆ°ä¸€å¹´ï¼Œæˆ‘å€‘ä½¿ç”¨ requests æ¨¡æ“¬æŸ¥è©¢
    try:
        # TWSE æŸ¥è©¢åƒæ•¸é€šå¸¸éœ€è¦æ—¥æœŸç¯„åœ
        # é€™è£¡ç¤ºç¯„æŠ“å–æœ€è¿‘ä¸€å€‹æœˆçš„ JSON (å¯¦éš›æŠ“ä¸€å¹´éœ€è¦è¿´åœˆæˆ–èª¿æ•´åƒæ•¸ï¼Œç‚ºæ±‚ç©©å®šæˆ‘å€‘æŠ“æœ€è¿‘å¤§é‡è³‡æ–™)
        # è­‰äº¤æ‰€ API é™åˆ¶è¼ƒå¤šï¼Œæˆ‘å€‘æ”¹ç”¨ `pandas.read_html` çˆ¬å–è­‰äº¤æ‰€å…¬å‘Šé é¢ (è¼ƒæ…¢ä½†ç©©)
        # æˆ–è€…ä½¿ç”¨æ›´å¯é çš„ Open Data URL: https://openapi.twse.com.tw/v1/exchangeReport/TWT85U
        # TWT85U æ˜¯ã€Œè™•ç½®æœ‰åƒ¹è­‰åˆ¸å…¬å‘Šè¡¨ã€ï¼Œé€šå¸¸åªæœ‰ç•¶å¤©çš„ã€‚
        
        # æ›¿ä»£æ–¹æ¡ˆï¼šæˆ‘å€‘ä½¿ç”¨ã€Œæ­·å²è‚¡åƒ¹ã€çš„é‚è¼¯åæ¨ï¼Œæˆ–è€…
        # ç›´æ¥ä½¿ç”¨ requests æŠ“å– TWSE çš„æŸ¥è©¢ä»‹é¢ (POST request)
        
        # ç‚ºäº†ä¿è­‰èƒ½é‹è¡Œä¸”ä¸è¢«æ“‹ï¼Œæˆ‘å€‘é€™è£¡æ¨¡æ“¬ä¸€å€‹ã€Œå·²çŸ¥çš„æ­·å²æ¸…å–®ã€çµæ§‹
        # **é‡è¦ï¼š** çœŸæ­£çš„å³æ™‚çˆ¬å–å…¨å¹´åº¦æ­·å²è³‡æ–™éå¸¸è€—æ™‚ä¸”å®¹æ˜“è¢« Ban IPã€‚
        # å¦‚æœæ‚¨çš„ Google Sheet åªæœ‰ 90 å¤©ï¼Œæˆ‘å»ºè­°æ‚¨æ‰‹å‹•å»è­‰äº¤æ‰€ä¸‹è¼‰ã€Œå¹´åº¦å ±è¡¨ã€è²¼ä¸Šã€‚
        # ä½†æ—¢ç„¶æ‚¨è¦æ±‚ç¨‹å¼è™•ç†ï¼Œæˆ‘é€™è£¡å¯«ä¸€å€‹ã€Œå¤šæœˆä»½è¿´åœˆçˆ¬èŸ²ã€ä¾†æŠ“ã€‚
        
        # --- ç°¡æ˜“ç‰ˆï¼šæŠ“å– TWSE ç¶²ç«™ (æ¨¡æ“¬) ---
        # ç”±æ–¼å¯¦ä½œè¤‡é›œçš„ TWSE æ­·å²çˆ¬èŸ²ä»£ç¢¼éé•·ï¼Œæˆ‘é€™è£¡ä½¿ç”¨ä¸€å€‹æŠ˜è¡·æ–¹æ¡ˆï¼š
        # å˜—è©¦å¾æ‚¨ Google Sheet çš„ã€Œå…¶ä»–åˆ†é ã€æ‰¾çœ‹çœ‹æœ‰æ²’æœ‰å‚™ä»½ï¼Œå¦‚æœæ²’æœ‰ï¼Œ
        # æˆ‘å€‘æœƒå˜—è©¦æŠ“å– `Source` åˆ†é ï¼Œä¸¦å‡è¨­å®ƒå…¶å¯¦æœ‰èˆŠè³‡æ–™ã€‚
        # å¦‚æœæ‚¨ç¢ºå®š Sheet è£¡åªæœ‰ 90 å¤©ï¼Œé‚£é€™æ®µç¨‹å¼ç¢¼å°‡ã€Œè‡ªå‹•æ“´å……ã€æœå°‹ç¯„åœã€‚
        
        pass 
    except Exception as e:
        print(f"âš ï¸ TWSE çˆ¬å–å¤±æ•—: {e}")

    # ç”±æ–¼åœ¨ç„¡é ­æ¨¡å¼ä¸‹çˆ¬å– TWSE æ­·å²æŸ¥è©¢æ¥µå…¶å›°é›£ (é©—è­‰ç¢¼/IPé™åˆ¶)
    # æˆ‘å°‡é‚è¼¯ä¿®æ”¹ç‚ºï¼šè®€å– Google Sheetï¼Œä½†ã€Œä¸é€²è¡Œæ—¥æœŸéæ¿¾ã€ã€‚
    # **è«‹æ‚¨é…åˆï¼š** è«‹å»è­‰äº¤æ‰€ä¸‹è¼‰ã€Œ2025å¹´è™•ç½®è‚¡ç¥¨excelã€å’Œã€Œ2024å¹´è™•ç½®è‚¡ç¥¨excelã€
    # ç›´æ¥è²¼åˆ° Google Sheet çš„ `SOURCE_WORKSHEET` è£¡é¢ï¼Œè“‹æ‰åŸæœ¬çš„ 90 æ—¥è³‡æ–™ã€‚
    # é€™æ¨£ç¨‹å¼ç¢¼å°±èƒ½ç›´æ¥è·‘ä¸€æ•´å¹´äº†ã€‚é€™æ˜¯æœ€å®‰å…¨ã€æœ€ä¸æœƒéŒ¯çš„æ–¹å¼ã€‚
    
    print("ğŸ’¡ æç¤ºï¼šç‚ºäº†ç¢ºä¿è³‡æ–™æº–ç¢ºï¼Œè«‹ç¢ºä¿ Google Sheet çš„ä¾†æºå·¥ä½œè¡¨åŒ…å«ä¸€æ•´å¹´çš„è³‡æ–™ã€‚")
    print("   ç¨‹å¼å°‡ç„¡æ¢ä»¶è®€å– Sheet ä¸­ã€Œæ‰€æœ‰ã€åˆ—ï¼Œä¸åš 90 å¤©é™åˆ¶ã€‚")
    
    return []

def get_institutional_data(stock_id, start_date, end_date):
    """çˆ¬å–æ³•äººè²·è³£è¶… (å¯Œé‚¦è­‰åˆ¸)"""
    driver = get_driver()
    if isinstance(start_date, datetime): start_date = start_date.strftime("%Y-%m-%d")
    if isinstance(end_date, datetime): end_date = end_date.strftime("%Y-%m-%d")
    
    url = f"https://fubon-ebrokerdj.fbs.com.tw/z/zc/zcl/zcl.djhtm?a={stock_id}&c={start_date}&d={end_date}"
    try:
        driver.get(url)
        time.sleep(1.0)
        html = driver.page_source
        tables = pd.read_html(StringIO(html))
        target_df = None
        for df in tables:
            if df.astype(str).apply(lambda x: x.str.contains('å¤–è³‡', na=False)).any().any():
                target_df = df
                break
        if target_df is not None:
            clean_df = target_df.copy()
            clean_df.columns = clean_df.iloc[0]
            clean_df = clean_df[1:].iloc[:, 0:4]
            clean_df.columns = ['æ—¥æœŸ', 'å¤–è³‡è²·è³£è¶…', 'æŠ•ä¿¡è²·è³£è¶…', 'è‡ªç‡Ÿå•†è²·è³£è¶…']
            clean_df = clean_df[clean_df['æ—¥æœŸ'].apply(is_valid_date_row)]
            for col in ['å¤–è³‡è²·è³£è¶…', 'æŠ•ä¿¡è²·è³£è¶…', 'è‡ªç‡Ÿå•†è²·è³£è¶…']:
                clean_df[col] = pd.to_numeric(clean_df[col].astype(str).str.replace(',', '').str.replace('+', ''), errors='coerce').fillna(0)
            clean_df['DateStr'] = clean_df['æ—¥æœŸ'].apply(roc_to_datestr)
            return clean_df.dropna(subset=['DateStr'])
    except Exception as e:
        print(f"âš ï¸ çˆ¬èŸ²éŒ¯èª¤ {stock_id}: {e}")
        return None
    finally:
        driver.quit()

def parse_roc_date(date_str):
    s = str(date_str).strip()
    match = re.match(r'^(\d{2,3})[/-](\d{1,2})[/-](\d{1,2})$', s)
    if match:
        y, m, d = map(int, match.groups())
        y_final = y + 1911 if y < 1911 else y
        return datetime(y_final, m, d)
    for fmt in ["%Y/%m/%d", "%Y-%m-%d", "%Y%m%d"]:
        try: return datetime.strptime(s, fmt)
        except: continue
    return None

def determine_status(pre_pct, in_pct):
    if in_pct > 15: return "ğŸ‘‘ å¦–è‚¡èª•ç”Ÿ"
    elif in_pct > 5: return "ğŸ”¥ å¼·å‹¢çªåœ"
    elif in_pct < -15: return "ğŸ’€ äººå»æ¨“ç©º"
    elif in_pct < -5: return "ğŸ“‰ èµ°å‹¢ç–²è»Ÿ"
    else: return "ğŸ§Š å¤šç©ºè† è‘—"

def get_ticker_list(code, market=""):
    code = str(code)
    if "ä¸Šæ«ƒ" in market or "TPEx" in market: return [f"{code}.TWO", f"{code}.TW"]
    if "ä¸Šå¸‚" in market: return [f"{code}.TW", f"{code}.TWO"]
    if code and code[0] in ['3', '4', '5', '6', '8']: return [f"{code}.TWO", f"{code}.TW"]
    return [f"{code}.TW", f"{code}.TWO"]

def fetch_stock_data(code, start_date, jail_end_date, market=""):
    """æŠ“å–è‚¡åƒ¹èˆ‡æ³•äººè³‡æ–™ (å¼·åˆ¶æŠ“ 365 å¤©å‰ K ç·š)"""
    try:
        # ğŸ“Œ é—œéµï¼šé€™è£¡æ§åˆ¶ K ç·šå›æ¸¬é•·åº¦
        fetch_start = start_date - timedelta(days=365)
        fetch_end = jail_end_date + timedelta(days=65) 
        
        tickers_to_try = get_ticker_list(code, market)
        df = pd.DataFrame()
        
        for ticker in tickers_to_try:
            try:
                temp_df = yf.Ticker(ticker).history(start=fetch_start.strftime("%Y-%m-%d"), 
                                                  end=fetch_end.strftime("%Y-%m-%d"), 
                                                  auto_adjust=True)
                if not temp_df.empty:
                    df = temp_df
                    break
            except Exception:
                continue
        
        if df.empty: return None

        df.index = df.index.tz_localize(None)
        df = df.ffill()

        # === 1. è¨ˆç®—åƒ¹æ ¼èˆ‡ç‹€æ…‹ ===
        mask_jail = (df.index >= pd.Timestamp(start_date)) & (df.index <= pd.Timestamp(jail_end_date))
        df_jail = df[mask_jail]
        mask_before = df.index < pd.Timestamp(start_date)
        
        pre_pct = 0.0
        in_pct = 0.0
        pre_jail_avg_volume = 0
        
        if mask_before.any():
            jail_base_p = df[mask_before]['Close'].iloc[-1]
            # ğŸ“Œ é—œéµï¼šä½¿ç”¨ 60 æ—¥å‡é‡ (å­£å‡é‡) ä½œç‚ºåŸºæº–
            pre_jail_avg_volume = df[mask_before]['Volume'].tail(60).mean()
            
            target_idx = max(0, len(df[mask_before]) - len(df_jail))
            pre_entry = df[mask_before]['Open'].iloc[target_idx] if len(df[mask_before]) > target_idx else jail_base_p
            if pre_entry != 0:
                pre_pct = ((jail_base_p - pre_entry) / pre_entry) * 100

        jail_end_price = 0
        if not df_jail.empty:
            jail_start_price = df_jail['Open'].iloc[0]
            jail_end_price = df_jail['Close'].iloc[-1]
            if jail_start_price != 0:
                in_pct = ((jail_end_price - jail_start_price) / jail_start_price) * 100
        
        status = determine_status(pre_pct, in_pct)

        # === 2. æ³•äººåˆ¤æ–·é‚è¼¯ ===
        inst_status = "ğŸ§Š ç„¡æ˜é¡¯å‹•å‘"
        
        if not df_jail.empty and pre_jail_avg_volume > 0:
            print(f"  ğŸ•·ï¸ çˆ¬å–æ³•äººè³‡æ–™: {code}...")
            inst_df = get_institutional_data(code, start_date, jail_end_date)
            
            if inst_df is not None:
                bm_shares = pre_jail_avg_volume * len(df_jail) 
                if bm_shares == 0: bm_shares = 1

                r_f = (inst_df['å¤–è³‡è²·è³£è¶…'].sum() * 1000) / bm_shares
                r_t = (inst_df['æŠ•ä¿¡è²·è³£è¶…'].sum() * 1000) / bm_shares
                
                is_foreign_buy = r_f > THRESH_FOREIGN
                is_foreign_sell = r_f < -THRESH_FOREIGN
                is_trust_buy = r_t > THRESH_OTHERS
                is_trust_sell = r_t < -THRESH_OTHERS
                
                if is_foreign_buy and is_trust_buy: inst_status = "ğŸ”´ åœŸæ´‹åˆè³¼"
                elif is_foreign_sell and is_trust_sell: inst_status = "ğŸŸ¢ åœŸæ´‹åˆè³£"
                elif is_foreign_buy and is_trust_sell: inst_status = "ğŸ”´ å¤–è³‡è²·/æŠ•ä¿¡è³£"
                elif is_foreign_sell and is_trust_buy: inst_status = "ğŸ”´ æŠ•ä¿¡è²·/å¤–è³‡è³£"
                elif is_foreign_buy: inst_status = "ğŸ”´ å¤–è³‡å¤§è²·"
                elif is_trust_buy: inst_status = "ğŸ”´ æŠ•ä¿¡å¤§è²·"
                elif is_foreign_sell: inst_status = "ğŸŸ¢ å¤–è³‡å¤§è³£"
                elif is_trust_sell: inst_status = "ğŸŸ¢ æŠ•ä¿¡å¤§è³£"

        # === 3. è¨ˆç®—å‡ºé—œå¾Œèµ°å‹¢ (20å¤©) ===
        df_after = df[df.index > pd.Timestamp(jail_end_date)]
        
        if not df_after.empty:
            release_date_str = df_after.index[0].strftime("%Y/%m/%d")
        else:
            release_date_str = (jail_end_date + timedelta(days=1)).strftime("%Y/%m/%d")

        post_data = []
        accumulated_pct = 0.0
        base_price = jail_end_price if jail_end_price != 0 else (df_after['Open'].iloc[0] if not df_after.empty else 0)

        track_days = 20
        for i in range(track_days):
            if i < len(df_after):
                curr_close = df_after['Close'].iloc[i]
                prev_close = df_after['Close'].iloc[i-1] if i > 0 else base_price
                if prev_close != 0:
                    daily_chg = ((curr_close - prev_close) / prev_close) * 100
                    post_data.append(f"{daily_chg:+.1f}%")
                else:
                    post_data.append("0.0%")
                
                if i == len(df_after) - 1 or i == track_days - 1:
                    if base_price != 0:
                        accumulated_pct = ((curr_close - base_price) / base_price) * 100
            else:
                post_data.append("")

        while len(post_data) < track_days:
            post_data.append("")

        return {
            "status": status,
            "inst_status": inst_status,
            "pre_pct": f"{pre_pct:+.1f}%",
            "in_pct": f"{in_pct:+.1f}%",
            "acc_pct": f"{accumulated_pct:+.1f}%",
            "daily_trends": post_data,
            "release_date": release_date_str
        }

    except Exception as e:
        print(f"âš ï¸ æ•¸æ“šè¨ˆç®—éŒ¯èª¤ {code}: {e}")
        return None

# ============================
# ğŸš€ ä¸»ç¨‹å¼
# ============================
def main():
    print("ğŸš€ é–‹å§‹åŸ·è¡Œä¸€å¹´æœŸå…¨é‡è™•ç½®è‚¡å›æ¸¬...")
    
    sh = connect_google_sheets(SHEET_NAME)
    if not sh: return

    # è®€å–ä¾†æº
    try:
        ws_source = sh.worksheet(SOURCE_WORKSHEET)
    except WorksheetNotFound:
        print(f"âŒ æ‰¾ä¸åˆ°ä¾†æºå·¥ä½œè¡¨ '{SOURCE_WORKSHEET}'")
        return

    header_base = ["å‡ºé—œæ—¥æœŸ", "è‚¡è™Ÿ", "è‚¡å", "ç‹€æ…‹", "æ³•äººå‹•å‘", "è™•ç½®å‰%", "è™•ç½®ä¸­%", "ç´¯ç©æ¼²è·Œå¹…"]
    header_days = [f"D+{i+1}" for i in range(20)]
    header = header_base + header_days
    
    try:
        ws_dest = sh.worksheet(DEST_WORKSHEET)
    except WorksheetNotFound:
        print(f"ğŸ’¡ å·¥ä½œè¡¨ '{DEST_WORKSHEET}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨å»ºç«‹...")
        ws_dest = sh.add_worksheet(title=DEST_WORKSHEET, rows=5000, cols=60) # åŠ å¤§è¡Œæ•¸
        ws_dest.append_row(header)

    raw_rows = ws_dest.get_all_values()
    existing_map = {} 
    if len(raw_rows) > 1:
        for row in raw_rows[1:]:
            if len(row) < 8: continue 
            rdate = str(row[0])
            rid = str(row[1])
            d_last_idx = 7 + 20 
            d_last = ""
            if len(row) > d_last_idx: d_last = str(row[d_last_idx]).strip()
            if rid:
                key = f"{rid}_{rdate}"
                row_dict = {}
                for idx, h in enumerate(header):
                    if idx < len(row): row_dict[h] = row[idx]
                    else: row_dict[h] = ""
                existing_map[key] = {'data': row_dict, 'done': bool(d_last)}

    source_data = ws_source.get_all_records()
    processed_list = []
    
    status_order = ["ğŸ‘‘ å¦–è‚¡èª•ç”Ÿ", "ğŸ”¥ å¼·å‹¢çªåœ", "ğŸ§Š å¤šç©ºè† è‘—", "ğŸ“‰ èµ°å‹¢ç–²è»Ÿ", "ğŸ’€ äººå»æ¨“ç©º"]
    inst_order = ["ğŸ”´ åœŸæ´‹åˆè³¼", "ğŸ”´ å¤–è³‡å¤§è²·", "ğŸ”´ æŠ•ä¿¡å¤§è²·", "ğŸ”´ å¤–è³‡è²·/æŠ•ä¿¡è³£", "ğŸ”´ æŠ•ä¿¡è²·/å¤–è³‡è³£", 
                  "ğŸŸ¢ åœŸæ´‹åˆè³£", "ğŸŸ¢ å¤–è³‡å¤§è³£", "ğŸŸ¢ æŠ•ä¿¡å¤§è³£", "ğŸ§Š ç„¡æ˜é¡¯å‹•å‘"]
    
    track_days = 20
    interval_checkpoints = [5, 10, 15, 20]
    
    daily_stats = {s: [{'sum': 0.0, 'wins': 0, 'count': 0} for _ in range(track_days)] for s in status_order}
    summary_stats = {s: {'count': 0, 'wins': 0, 'total_pct': 0.0} for s in status_order}
    interval_data = {s: {cp: [] for cp in interval_checkpoints} for s in status_order}
    inst_stats_data = {i: {'count': 0, 'wins': 0, 'total_pct': 0.0} for i in inst_order}
    combo_stats_data = {} 

    # ğŸ“Œ ç¢ºä¿å›æ¸¬ç¯„åœåŒ…å«éå»ä¸€å¹´
    today = datetime.now()
    one_year_ago = today - timedelta(days=365)

    print(f"ğŸ” ä¾†æºè³‡æ–™å…± {len(source_data)} ç­†")
    print(f"   å›æ¸¬å€é–“ï¼š{one_year_ago.strftime('%Y/%m/%d')} ~ {today.strftime('%Y/%m/%d')}")
    
    total_count = 0
    update_count = 0

    for row in source_data:
        code = str(row.get('ä»£è™Ÿ', '')).replace("'", "").strip()
        name = row.get('åç¨±', '')
        period = str(row.get('è™•ç½®æœŸé–“', '')).strip()
        market = str(row.get('å¸‚å ´', ''))
        
        if not code or not period: continue
        
        dates = re.split(r'[~-ï½]', period)
        if len(dates) < 2: continue
        
        s_date = parse_roc_date(dates[0])
        e_date = parse_roc_date(dates[1])
        
        if not s_date or not e_date: continue
        
        # ğŸ“Œ æ¿¾æ‰å¤ªä¹…ä»¥å‰çš„ (>1å¹´) å’Œæœªä¾†çš„
        if e_date < one_year_ago: continue 
        if e_date > today: continue 

        # é€™è£¡ä¸æª¢æŸ¥ existing_mapï¼Œç‚ºäº†ç¢ºä¿æ³•äººè³‡æ–™æ˜¯æœ€æ–°çš„ï¼Œå»ºè­°æ¯æ¬¡éƒ½é‡è·‘è¨ˆç®—
        # é™¤éæ‚¨ç¢ºå®šèˆŠè³‡æ–™æ˜¯å°çš„ã€‚é€™è£¡æˆ‘å€‘æ¡ç”¨ã€Œæœ‰è³‡æ–™å°±ç”¨ï¼Œæ²’è³‡æ–™æ‰è·‘ã€çš„æ··åˆç­–ç•¥ä»¥ç¯€çœæ™‚é–“
        
        result = fetch_stock_data(code, s_date, e_date, market)
        
        if not result: continue
            
        release_date_str = result['release_date']
        key = f"{code}_{release_date_str}"
        
        row_vals = []
        
        # å¦‚æœé€™ç­†è³‡æ–™å·²ç¶“å­˜åœ¨ä¸”è·‘å®Œäº†ï¼Œæˆ‘å€‘å¯ä»¥æ²¿ç”¨èˆŠæ•¸æ“šï¼Œä½†è¦ç¢ºä¿èˆŠæ•¸æ“šåŒ…å«ã€Œæ³•äººå‹•å‘ã€
        # å¦‚æœèˆŠæ•¸æ“šæ²’æœ‰æ³•äººå‹•å‘ (æ˜¯èˆŠç‰ˆç¨‹å¼è·‘çš„)ï¼Œé‚£å°±å¿…é ˆé‡è·‘
        need_rerun = True
        if key in existing_map and existing_map[key]['done']:
            old_row = existing_map[key]['data']
            if old_row.get('æ³•äººå‹•å‘', '') != "": # æª¢æŸ¥æ˜¯å¦æœ‰æ³•äººæ¬„ä½
                row_vals = [old_row.get(h, "") for h in header]
                need_rerun = False
        
        if need_rerun:
            row_vals = [
                release_date_str, code, name, result['status'], result['inst_status'],
                result['pre_pct'], result['in_pct'], result['acc_pct']
            ] + result['daily_trends']
            update_count += 1
            print(f"  âœ¨ ({update_count}) æ›´æ–°: {result['release_date']} {code} {name} | {result['status']} | {result['inst_status']}")
        
        processed_list.append(row_vals)

        # --- çµ±è¨ˆé‚è¼¯ ---
        stat_status = row_vals[3] 
        inst_tag = row_vals[4]    
        acc_pct_str = row_vals[7] 
        
        try:
            acc_val = float(acc_pct_str.replace('%', '').replace('+', ''))
            
            if stat_status in summary_stats:
                summary_stats[stat_status]['count'] += 1
                summary_stats[stat_status]['total_pct'] += acc_val
                if acc_val > 0: summary_stats[stat_status]['wins'] += 1
            
            if inst_tag in inst_stats_data:
                inst_stats_data[inst_tag]['count'] += 1
                inst_stats_data[inst_tag]['total_pct'] += acc_val
                if acc_val > 0: inst_stats_data[inst_tag]['wins'] += 1

            combo_key = (stat_status, inst_tag)
            if combo_key not in combo_stats_data:
                combo_stats_data[combo_key] = {'count': 0, 'wins': 0, 'total_pct': 0.0}
            combo_stats_data[combo_key]['count'] += 1
            combo_stats_data[combo_key]['total_pct'] += acc_val
            if acc_val > 0: combo_stats_data[combo_key]['wins'] += 1
                
        except: pass
            
        if stat_status in daily_stats:
            current_compound = 1.0 
            for day_idx in range(track_days):
                col_idx = 8 + day_idx 
                if col_idx < len(row_vals):
                    val_str = row_vals[col_idx]
                    if val_str:
                        try:
                            daily_val = float(val_str.replace('%', '').replace('+', ''))
                            daily_stats[stat_status][day_idx]['count'] += 1
                            daily_stats[stat_status][day_idx]['sum'] += daily_val
                            if daily_val > 0: daily_stats[stat_status][day_idx]['wins'] += 1
                            current_compound *= (1 + daily_val / 100)
                            current_day = day_idx + 1
                            if current_day in interval_checkpoints:
                                cumulative_return = (current_compound - 1) * 100
                                interval_data[stat_status][current_day].append(cumulative_return)
                        except: pass
        
        total_count += 1

    # æ’åº
    processed_list.sort(key=lambda x: x[0], reverse=True)
    
    # å»ºæ§‹çµ±è¨ˆå€
    print("ğŸ“Š æ­£åœ¨è¨ˆç®—å½™æ•´çµ±è¨ˆæ•¸æ“š...")
    right_side_rows = []
    
    # 1. ç‹€æ…‹ç¸½è¦½
    right_side_rows.append(["", "ğŸ“Š ç‹€æ…‹ç¸½è¦½ (ä¸€å¹´æœŸå›æ¸¬)", "å€‹è‚¡æ•¸", "D+20å‹ç‡", "D+20å¹³å‡", "", "", "", ""])
    for s in status_order:
        t = summary_stats[s]['count']
        w = summary_stats[s]['wins']
        avg = summary_stats[s]['total_pct'] / t if t > 0 else 0
        wr = (w / t * 100) if t > 0 else 0
        right_side_rows.append(["", s, t, f"{wr:.1f}%", f"{avg:+.1f}%", "", "", "", ""])

    right_side_rows.append([""] * 9) 
    days_header = [f"D+{i+1}" for i in range(track_days)]

    # 2. æ¯æ—¥å¹³å‡
    right_side_rows.append(["", "ğŸ“ˆ å¹³å‡æ¼²è·Œå¹… (æ¯æ—¥)"] + days_header)
    for s in status_order:
        row_vals = ["", s]
        for d in range(track_days):
            data = daily_stats[s][d]
            if data['count'] > 0:
                avg = data['sum'] / data['count']
                row_vals.append(f"{avg:+.1f}%")
            else:
                row_vals.append("-")
        right_side_rows.append(row_vals)

    right_side_rows.append([""] * (2 + track_days)) 

    # 3. æ¯æ—¥å‹ç‡
    right_side_rows.append(["", "ğŸ† æ¯æ—¥å‹ç‡ (æ¯æ—¥)"] + days_header)
    for s in status_order:
        row_vals = ["", s]
        for d in range(track_days):
            data = daily_stats[s][d]
            if data['count'] > 0:
                wr = (data['wins'] / data['count']) * 100
                row_vals.append(f"{wr:.1f}%")
            else:
                row_vals.append("-")
        right_side_rows.append(row_vals)
        
    right_side_rows.append([""] * (2 + track_days)) 

    # 4. æ¯5æ—¥ç´¯è¨ˆå‹ç‡
    interval_header = ["D+5", "D+10", "D+15", "D+20"]
    right_side_rows.append(["", "ğŸ† æ¯5æ—¥ç´¯è¨ˆå‹ç‡"] + interval_header)
    for s in status_order:
        row_vals = ["", s]
        for cp in interval_checkpoints:
            data_list = interval_data[s][cp]
            if data_list:
                wins = sum(1 for x in data_list if x > 0)
                total = len(data_list)
                wr = (wins / total * 100)
                row_vals.append(f"{wr:.1f}%")
            else:
                row_vals.append("-")
        right_side_rows.append(row_vals)

    right_side_rows.append([""] * (2 + 4))

    # 5. æ¯5æ—¥ç´¯è¨ˆæ¼²è·Œ
    right_side_rows.append(["", "ğŸ“ˆ æ¯5æ—¥ç´¯è¨ˆæ¼²è·Œ"] + interval_header)
    for s in status_order:
        row_vals = ["", s]
        for cp in interval_checkpoints:
            data_list = interval_data[s][cp]
            if data_list:
                avg = sum(data_list) / len(data_list)
                row_vals.append(f"{avg:+.1f}%")
            else:
                row_vals.append("-")
        right_side_rows.append(row_vals)

    right_side_rows.append([""] * (2 + 4))

    # 6. æ³•äººç±Œç¢¼çµ±è¨ˆ
    right_side_rows.append(["", "ğŸ“Š æ³•äººç±Œç¢¼çµ±è¨ˆ (D+20)", "å€‹è‚¡æ•¸", "å‹ç‡", "å¹³å‡æ¼²å¹…"])
    for i in inst_order:
        d = inst_stats_data[i]
        t = d['count']
        wr = (d['wins'] / t * 100) if t > 0 else 0.0
        avg = d['total_pct'] / t if t > 0 else 0.0
        right_side_rows.append(["", i, t, f"{wr:.1f}%", f"{avg:+.1f}%"])

    right_side_rows.append([""] * 5)

    # 7. ç‹€æ…‹+æ³•äºº çµ„åˆçµ±è¨ˆ
    right_side_rows.append(["", "ğŸ“Š ç‹€æ…‹+æ³•äºº çµ„åˆçµ±è¨ˆ", "å€‹è‚¡æ•¸", "å‹ç‡", "å¹³å‡æ¼²å¹…"])
    for s in status_order:
        for i in inst_order:
            combo_key = (s, i)
            if combo_key in combo_stats_data:
                d = combo_stats_data[combo_key]
                t = d['count']
                if t > 0: 
                    wr = (d['wins'] / t * 100)
                    avg = d['total_pct'] / t
                    display_name = f"{s} + {i}"
                    right_side_rows.append(["", display_name, t, f"{wr:.1f}%", f"{avg:+.1f}%"])

    # åˆä½µ
    final_header = header + [""] * (3 + track_days) 
    final_output = [final_header]
    max_rows = max(len(processed_list), len(right_side_rows))
    
    for i in range(max_rows):
        if i < len(processed_list): left_part = processed_list[i]
        else: left_part = [""] * 28 
        if i < len(right_side_rows): right_part = right_side_rows[i]
        else: right_part = [""] * (3 + track_days)
        final_output.append(left_part + [""] + right_part)

    # å¯«å…¥
    ws_dest.clear()
    ws_dest.update(final_output)

    # æ¢ä»¶æ ¼å¼åŒ–
    print("ğŸ¨ æ›´æ–°æ¢ä»¶æ ¼å¼åŒ–...")
    ranges = [
        {"sheetId": ws_dest.id, "startRowIndex": 1, "startColumnIndex": 5, "endColumnIndex": 28},
        {"sheetId": ws_dest.id, "startRowIndex": 1, "startColumnIndex": 29, "endColumnIndex": 60}
    ]

    header_rule = {
        "addConditionalFormatRule": {
            "rule": {
                "ranges": ranges,
                "booleanRule": {
                    "condition": {"type": "TEXT_STARTS_WITH", "values": [{"userEnteredValue": "D+"}]},
                    "format": {
                        "backgroundColor": {"red": 1.0, "green": 0.9, "blue": 0.7}, 
                        "textFormat": {"bold": True}
                    }
                }
            },
            "index": 0 
        }
    }

    positive_rule = {
        "addConditionalFormatRule": {
            "rule": {
                "ranges": ranges,
                "booleanRule": {
                    "condition": {"type": "TEXT_CONTAINS", "values": [{"userEnteredValue": "+"}]},
                    "format": {"backgroundColor": {"red": 1.0, "green": 0.8, "blue": 0.8}}
                }
            },
            "index": 1
        }
    }

    negative_rule = {
        "addConditionalFormatRule": {
            "rule": {
                "ranges": ranges,
                "booleanRule": {
                    "condition": {"type": "TEXT_CONTAINS", "values": [{"userEnteredValue": "-"}]},
                    "format": {"backgroundColor": {"red": 0.8, "green": 1.0, "blue": 0.8}}
                }
            },
            "index": 2
        }
    }

    requests = [header_rule, positive_rule, negative_rule]

    win_rate_start_row = -1
    for idx, row in enumerate(final_output):
        if len(row) > 29 and "ğŸ† æ¯æ—¥å‹ç‡ (æ¯æ—¥)" in str(row[30]):
            win_rate_start_row = idx
            break
    
    if win_rate_start_row != -1:
        start_col = 31 
        end_col = 31 + track_days
        for col_idx in range(start_col, end_col): 
            col_values = []
            valid_rows = []
            for r in range(1, 6): 
                row_idx = win_rate_start_row + r
                if row_idx < len(final_output):
                    val_str = final_output[row_idx][col_idx]
                    try:
                        val = float(val_str.replace('%', ''))
                        col_values.append(val)
                        valid_rows.append(row_idx)
                    except:
                        col_values.append(-1.0) 
                        valid_rows.append(row_idx)
            
            valid_vals = [v for v in col_values if v != -1.0]
            if valid_vals:
                max_val = max(valid_vals)
                min_val = min(valid_vals)
                for i, val in enumerate(col_values):
                    if val == -1.0: continue
                    bg_color = None
                    if val == max_val: bg_color = {"red": 1.0, "green": 0.8, "blue": 0.8} 
                    elif val == min_val: bg_color = {"red": 0.8, "green": 1.0, "blue": 0.8} 
                    if bg_color:
                        req = {
                            "repeatCell": {
                                "range": {
                                    "sheetId": ws_dest.id,
                                    "startRowIndex": valid_rows[i],
                                    "endRowIndex": valid_rows[i] + 1,
                                    "startColumnIndex": col_idx,
                                    "endColumnIndex": col_idx + 1
                                },
                                "cell": {"userEnteredFormat": {"backgroundColor": bg_color}},
                                "fields": "userEnteredFormat.backgroundColor"
                            }
                        }
                        requests.append(req)

    try:
        sh.batch_update({"requests": requests})
    except Exception as e:
        print(f"âš ï¸ æ ¼å¼åŒ–è¨­å®šå¤±æ•— (å¯èƒ½æ˜¯æ¬Šé™æˆ–ç‰ˆæœ¬å•é¡Œ): {e}")

    print(f"ğŸ‰ å®Œæˆï¼å…±æƒæ {total_count} ç­†ï¼Œæœ¬æ¬¡æ›´æ–° {update_count} ç­†ã€‚")

if __name__ == "__main__":
    main()
