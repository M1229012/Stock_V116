import gspread
import yfinance as yf
import pandas as pd
import numpy as np
import re
import time
import os
from datetime import datetime, timedelta
from google.oauth2.service_account import Credentials

# ============================
# âš™ï¸ è¨­å®šå€
# ============================
SOURCE_SHEET_NAME = "å°è‚¡æ³¨æ„è‚¡è³‡æ–™åº«_V33"
SOURCE_WORKSHEET = "è™•ç½®è‚¡90æ—¥æ˜ç´°"

DEST_SHEET_NAME = "è™•ç½®è‚¡å‡ºé—œè¨˜éŒ„"
DEST_WORKSHEET = "å‡ºé—œè¨˜éŒ„"

SERVICE_KEY_FILE = "service_key.json"

# ============================
# ğŸ› ï¸ å·¥å…·å‡½å¼
# ============================
def connect_google_sheets(sheet_name):
    """é€£ç·š Google Sheets"""
    try:
        scope = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        creds = Credentials.from_service_account_file(SERVICE_KEY_FILE, scopes=scope)
        gc = gspread.authorize(creds)
        sh = gc.open(sheet_name)
        return sh
    except Exception as e:
        print(f"âŒ Google Sheet é€£ç·šå¤±æ•— ({sheet_name}): {e}")
        return None

def parse_roc_date(date_str):
    """è§£ææ°‘åœ‹æˆ–è¥¿å…ƒæ—¥æœŸ"""
    s = str(date_str).strip()
    # è™•ç†æ°‘åœ‹å¹´ 113/01/01 æˆ– 113-01-01
    match = re.match(r'^(\d{2,3})[/-](\d{1,2})[/-](\d{1,2})$', s)
    if match:
        y, m, d = map(int, match.groups())
        y_final = y + 1911 if y < 1911 else y
        return datetime(y_final, m, d)
    # è™•ç†è¥¿å…ƒå¹´
    for fmt in ["%Y/%m/%d", "%Y-%m-%d", "%Y%m%d"]:
        try: return datetime.strptime(s, fmt)
        except: continue
    return None

def determine_status(pre_pct, in_pct):
    """åˆ¤æ–·è™•ç½®ç‹€æ…‹ (å…±ç”¨é‚è¼¯)"""
    if in_pct > 15: return "ğŸ‘‘ å¦–è‚¡èª•ç”Ÿ"
    elif in_pct > 5: return "ğŸ”¥ å¼·å‹¢çªåœ"
    elif in_pct < -15: return "ğŸ’€ äººå»æ¨“ç©º"
    elif in_pct < -5: return "ğŸ“‰ èµ°å‹¢ç–²è»Ÿ"
    else: return "ğŸ§Š å¤šç©ºè† è‘—"

def fetch_stock_data(code, start_date, jail_end_date):
    """
    æŠ“å–æ­·å²è‚¡åƒ¹ä¸¦è¨ˆç®—ï¼š
    1. ç‹€æ…‹ (è™•ç½®å‰/è™•ç½®ä¸­ %)
    2. å‡ºé—œå¾Œ 10 æ—¥èµ°å‹¢ (D+1 ~ D+10)
    """
    try:
        # è¨­å®šæŠ“å–ç¯„åœï¼šè™•ç½®å‰ 60 å¤© ~ å‡ºé—œå¾Œ 30 å¤© (ç¢ºä¿æœ‰è¶³å¤ æ•¸æ“š)
        fetch_start = start_date - timedelta(days=60)
        fetch_end = jail_end_date + timedelta(days=40) 
        
        suffix = ".TWO" if len(code) < 4 else ".TW" # ç°¡æ˜“åˆ¤æ–·ï¼Œè‹¥ä¸æº–ç¢ºå»ºè­°å¾ Sheet è®€å–å¸‚å ´åˆ¥
        # å˜—è©¦ä¸Šå¸‚æˆ–ä¸Šæ«ƒå¾Œç¶´
        ticker = f"{code}.TW"
        df = yf.Ticker(ticker).history(start=fetch_start, end=fetch_end, auto_adjust=True)
        if df.empty:
            ticker = f"{code}.TWO"
            df = yf.Ticker(ticker).history(start=fetch_start, end=fetch_end, auto_adjust=True)
        
        if df.empty: return None

        df.index = df.index.tz_localize(None)
        df = df.ffill() # è£œå‡æ—¥ç©ºå€¼

        # === 1. è¨ˆç®—è™•ç½®ç‹€æ…‹ ===
        # è™•ç½®ä¸­å€é–“
        mask_jail = (df.index >= pd.Timestamp(start_date)) & (df.index <= pd.Timestamp(jail_end_date))
        df_jail = df[mask_jail]
        
        # è™•ç½®å‰å€é–“
        mask_before = df.index < pd.Timestamp(start_date)
        
        pre_pct = 0.0
        in_pct = 0.0
        
        if not mask_before.any():
            pre_pct = 0.0
        else:
            jail_base_p = df[mask_before]['Close'].iloc[-1]
            # ç°¡å–®è¨ˆç®—ï¼šè™•ç½®å‰æœ€å¾Œæ”¶ç›¤ vs è™•ç½®ç¬¬ä¸€å¤©é–‹ç›¤ (æˆ–ä¾ä½ åŸæœ¬é‚è¼¯èª¿æ•´)
            # é€™è£¡æ²¿ç”¨ä½ ä¹‹å‰çš„é‚è¼¯æ¦‚å¿µ
            target_idx = max(0, len(df[mask_before]) - len(df_jail))
            pre_entry = df[mask_before]['Open'].iloc[target_idx] if len(df[mask_before]) > target_idx else jail_base_p
            if pre_entry != 0:
                pre_pct = ((jail_base_p - pre_entry) / pre_entry) * 100

        jail_end_price = 0
        if not df_jail.empty:
            jail_start_price = df_jail['Open'].iloc[0]
            jail_end_price = df_jail['Close'].iloc[-1]
            if jail_start_price != 0:
                in_pct = ((jail_end_price - jail_start_price) / jail_start_price) * 100
        
        status = determine_status(pre_pct, in_pct)

        # === 2. è¨ˆç®—å‡ºé—œå¾Œ D+1 ~ D+10 ===
        # æ‰¾å‡ºå¤§æ–¼è™•ç½®çµæŸæ—¥æœŸçš„äº¤æ˜“æ—¥
        df_after = df[df.index > pd.Timestamp(jail_end_date)]
        
        post_data = []
        accumulated_pct = 0.0
        
        # å‡ºé—œåŸºæº–åƒ¹ (é€šå¸¸æ˜¯è™•ç½®æœ€å¾Œä¸€å¤©çš„æ”¶ç›¤åƒ¹)
        base_price = jail_end_price if jail_end_price != 0 else (df_after['Open'].iloc[0] if not df_after.empty else 0)

        for i in range(10):
            if i < len(df_after):
                curr_close = df_after['Close'].iloc[i]
                # è¨ˆç®—ç•¶æ—¥æ¼²è·Œå¹… (vs å‰ä¸€æ—¥æ”¶ç›¤)
                prev_close = df_after['Close'].iloc[i-1] if i > 0 else base_price
                daily_chg = ((curr_close - prev_close) / prev_close) * 100
                post_data.append(f"{daily_chg:+.1f}%")
                
                # æ›´æ–°ç´¯ç©æ¼²è·Œå¹… (D+10 vs è™•ç½®çµæŸåƒ¹)
                if i == len(df_after) - 1 or i == 9:
                    if base_price != 0:
                        accumulated_pct = ((curr_close - base_price) / base_price) * 100
            else:
                post_data.append("") # æœªä¾†æ—¥æœŸç•™ç©º

        # è£œæ»¿ 10 æ ¼
        while len(post_data) < 10:
            post_data.append("")

        return {
            "status": status,
            "pre_pct": f"{pre_pct:+.1f}%",
            "in_pct": f"{in_pct:+.1f}%",
            "acc_pct": f"{accumulated_pct:+.1f}%",
            "daily_trends": post_data,
            "release_date": df_after.index[0].strftime("%Y/%m/%d") if not df_after.empty else "æœªçŸ¥"
        }

    except Exception as e:
        print(f"âš ï¸ æ•¸æ“šæŠ“å–éŒ¯èª¤ {code}: {e}")
        return None

# ============================
# ğŸš€ ä¸»ç¨‹å¼
# ============================
def main():
    print("ğŸš€ é–‹å§‹åŸ·è¡Œè™•ç½®è‚¡å‡ºé—œè¨˜éŒ„æ›´æ–°...")
    
    # 1. é€£ç·šè³‡æ–™åº«
    sh_source = connect_google_sheets(SOURCE_SHEET_NAME)
    sh_dest = connect_google_sheets(DEST_SHEET_NAME)
    
    if not sh_source or not sh_dest: return

    try:
        ws_source = sh_source.worksheet(SOURCE_WORKSHEET)
        ws_dest = sh_dest.worksheet(DEST_WORKSHEET)
    except Exception as e:
        print(f"âŒ æ‰¾ä¸åˆ°å·¥ä½œè¡¨: {e}")
        return

    # 2. è®€å–ç¾æœ‰è¨˜éŒ„ (é¿å…é‡è¤‡æŠ“å–å·²å®Œæˆçš„)
    existing_records = ws_dest.get_all_records()
    existing_map = {} # Key: "Code_ReleaseDate"
    
    # ç”¨ä¾†åˆ¤æ–·æ˜¯å¦éœ€è¦æ›´æ–°
    # æ ¼å¼: {'2330_2024-01-01': {'row_index': 2, 'd10_filled': True/False}}
    for i, row in enumerate(existing_records):
        rid = str(row.get('è‚¡è™Ÿ', ''))
        rdate = str(row.get('å‡ºé—œæ—¥æœŸ', ''))
        d10 = str(row.get('D+10', '')).strip()
        if rid and rdate:
            key = f"{rid}_{rdate}"
            existing_map[key] = {
                'data': row,
                'done': bool(d10) # å¦‚æœ D+10 æœ‰å€¼ï¼Œè¦–ç‚ºå·²çµæ¡ˆ
            }

    # 3. è®€å–è™•ç½®åå–®
    source_data = ws_source.get_all_records()
    processed_list = []
    
    today = datetime.now()

    print(f"ğŸ” æƒæ {len(source_data)} ç­†è™•ç½®ç´€éŒ„...")

    for row in source_data:
        code = str(row.get('ä»£è™Ÿ', '')).replace("'", "").strip()
        name = row.get('åç¨±', '')
        period = str(row.get('è™•ç½®æœŸé–“', '')).strip()
        
        if not code or not period: continue
        
        dates = re.split(r'[~-ï½]', period)
        if len(dates) < 2: continue
        
        s_date = parse_roc_date(dates[0])
        e_date = parse_roc_date(dates[1])
        
        if not s_date or not e_date: continue
        
        # åªè™•ç†ã€Œå·²ç¶“çµæŸã€æˆ–ã€Œä»Šå¤©çµæŸã€çš„è™•ç½® (æœªä¾†çš„ä¸è™•ç†)
        if e_date > today: continue

        # é ä¼°å‡ºé—œæ—¥ (è™•ç½®çµæŸæ—¥ + 1 å¤©ï¼Œä½†æº–ç¢ºæ—¥æœŸéœ€çœ‹ yfinance ç¬¬ä¸€ç­†äº¤æ˜“æ—¥)
        # å…ˆç”¨ key æª¢æŸ¥æ˜¯å¦å­˜åœ¨
        # ç”±æ–¼ yfinance æ‰èƒ½ç¢ºå®šæº–ç¢ºçš„å‡ºé—œäº¤æ˜“æ—¥ï¼Œé€™è£¡æˆ‘å€‘å…ˆåšåˆæ­¥éæ¿¾
        # å¦‚æœé€™ç­†è³‡æ–™å·²ç¶“åœ¨ Sheet è£¡ä¸” D+10 æ»¿äº†ï¼Œå°±ç›´æ¥ç”¨èˆŠè³‡æ–™
        
        # ç‚ºäº†æ¯”å°ï¼Œæˆ‘å€‘éœ€è¦å…ˆçŸ¥é“ã€Œå¤§æ¦‚ã€çš„å‡ºé—œæ—¥ï¼Œæˆ–æ˜¯æƒæ existing_map è£¡æœ‰æ²’æœ‰è©²ä»£è™Ÿä¸”æ—¥æœŸæ¥è¿‘çš„
        # é€™è£¡æ¡å–ç­–ç•¥ï¼šåªè¦æ˜¯å·²çµæŸçš„è™•ç½®ï¼Œéƒ½ä¸Ÿé€²å»è™•ç†ï¼Œä½†åœ¨ fetch å…§éƒ¨åšå¿«å–åˆ¤æ–·
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ä¸”å®Œæˆ
        # æ³¨æ„ï¼šå› ç‚ºå‡ºé—œæ—¥å¯èƒ½å› å‡æ—¥è®Šå‹•ï¼Œæˆ‘å€‘é€™è£¡ç„¡æ³•ç²¾ç¢ºçµ„å‡º Keyï¼Œ
        # æ‰€ä»¥ç­–ç•¥æ”¹ç‚ºï¼šä¸€å¾‹é‡æ–°è¨ˆç®—æ•¸æ“šï¼Œä½†å¦‚æœè³‡æ–™åº«å·²å­˜åœ¨è©²ä»£è™Ÿä¸”æ—¥æœŸç›¸è¿‘çš„å®Œæ•´ç´€éŒ„ï¼Œå‰‡å¯ä»¥ç”¨èˆŠçš„ã€‚
        # ç°¡å–®èµ·è¦‹ï¼šæˆ‘å€‘å°æ¯ä¸€ç­†éƒ½å»æŠ“ yfinance (å› ç‚º yfinance æœ‰å¿«å–ï¼Œä¸”åŸ·è¡Œé »ç‡ä¸é«˜)
        # æˆ–æ˜¯ï¼šåªå°ã€Œæœ€è¿‘ 30 å¤©å…§å‡ºé—œã€æˆ–ã€ŒD+10 æœªå¡«æ»¿ã€çš„åš fetch
        
        is_fully_done = False
        # ç°¡æ˜“æª¢æŸ¥ï¼šå¦‚æœçµæŸæ—¥æœŸè·ä»Šè¶…é 20 å¤©ï¼Œä¸”æˆ‘å€‘åœ¨ç¾æœ‰è³‡æ–™åº«æ‰¾ä¸åˆ°å®ƒï¼Œå¯èƒ½éœ€è¦è£œæŠ“
        # ä½†å¦‚æœæ‰¾åˆ°äº†ä¸” D+10 æœ‰å€¼ï¼Œå°± skip
        
        # é€™è£¡ç›´æ¥åŸ·è¡Œ fetchï¼Œé‚è¼¯æ¯”è¼ƒä¹¾æ·¨ï¼Œé›–ç„¶èŠ±é»æ™‚é–“ä½†ç¢ºä¿è³‡æ–™æ­£ç¢º
        # ç‚ºäº†é¿å… API é™åˆ¶ï¼Œå»ºè­°åŠ ä¸€é» delay
        
        print(f"è™•ç†: {code} {name} (è™•ç½®çµæŸ: {e_date.strftime('%Y-%m-%d')})...")
        
        result = fetch_stock_data(code, s_date, e_date)
        if not result:
            print(f"  âš ï¸ ç„¡æ³•æŠ“å–æ•¸æ“šï¼Œè·³é")
            continue
            
        release_date_str = result['release_date'] # æ ¼å¼ YYYY/MM/DD
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ä¸” D+10 å·²å¡«æ»¿
        key = f"{code}_{release_date_str}"
        if key in existing_map and existing_map[key]['done']:
            # ä½¿ç”¨èˆŠè³‡æ–™ (ä¿ç•™åŸæœ¬çš„è¨˜éŒ„ï¼Œé¿å…è¦†è“‹)
            old_row = existing_map[key]['data']
            processed_list.append([
                old_row.get('å‡ºé—œæ—¥æœŸ'), old_row.get('è‚¡è™Ÿ'), old_row.get('è‚¡å'),
                old_row.get('ç‹€æ…‹'), old_row.get('è™•ç½®å‰%'), old_row.get('è™•ç½®ä¸­%'),
                old_row.get('ç´¯ç©æ¼²è·Œå¹…'),
                old_row.get('D+1'), old_row.get('D+2'), old_row.get('D+3'), old_row.get('D+4'), old_row.get('D+5'),
                old_row.get('D+6'), old_row.get('D+7'), old_row.get('D+8'), old_row.get('D+9'), old_row.get('D+10')
            ])
            # print(f"  âœ… å·²å­˜åœ¨ä¸”å®Œæ•´ï¼Œè·³éæ›´æ–°")
        else:
            # æ–°è³‡æ–™ æˆ– éœ€è¦æ›´æ–°çš„è³‡æ–™
            row_data = [
                release_date_str,
                code,
                name,
                result['status'],
                result['pre_pct'],
                result['in_pct'],
                result['acc_pct']
            ] + result['daily_trends']
            
            processed_list.append(row_data)
            print(f"  âœ¨ æ›´æ–°æ•¸æ“š: {result['status']}")
            time.sleep(0.5) # é¿å…å¤ªå¿«

    # 4. æ’åºèˆ‡å¯«å…¥
    # ä¾æ—¥æœŸ (index 0) æ’åºï¼Œç”±æ–°åˆ°èˆŠ
    processed_list.sort(key=lambda x: x[0], reverse=True)
    
    # æº–å‚™å¯«å…¥ Header
    header = ["å‡ºé—œæ—¥æœŸ", "è‚¡è™Ÿ", "è‚¡å", "ç‹€æ…‹", "è™•ç½®å‰%", "è™•ç½®ä¸­%", "ç´¯ç©æ¼²è·Œå¹…", 
              "D+1", "D+2", "D+3", "D+4", "D+5", "D+6", "D+7", "D+8", "D+9", "D+10"]
    
    final_output = [header] + processed_list
    
    # æ¸…ç©ºä¸¦å¯«å…¥
    ws_dest.clear()
    ws_dest.update(final_output)
    print(f"ğŸ‰ å®Œæˆï¼å…±å¯«å…¥ {len(processed_list)} ç­†è³‡æ–™åˆ°ã€Œå‡ºé—œè¨˜éŒ„ã€ã€‚")

if __name__ == "__main__":
    main()
