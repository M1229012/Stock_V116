# -*- coding: utf-8 -*-
"""
V116.22 å¾Œç«¯æ•‘æ´ç‰ˆ (All-FinMind Core)
ä¿®æ­£é‡é»ï¼š
1. [ç§»é™¤ Yahoo] æ­·å²è‚¡åƒ¹ã€PEã€PB å…¨éƒ¨æ”¹ç”¨ FinMind æŠ“å–ï¼Œè§£æ±º Zeabur IP è¢«å°é–å°è‡´è³‡æ–™ç‚º 0 çš„å•é¡Œã€‚
2. [é¡åº¦è¨ˆç®—] ä¸€æª”è‚¡ç¥¨éœ€å‘¼å« 4 æ¬¡ API (è‚¡åƒ¹ã€PERã€PBRã€ç•¶æ²–)ï¼Œå› æ­¤æ¯å°æ™‚é™åˆ¶è™•ç† 120 æª”è‚¡ç¥¨ã€‚
3. [è³‡æ–™ä¿®å¾©] åŸ·è¡Œå¾Œå°‡è‡ªå‹•ä¿®å¾© Google Sheet ä¸­çš„ 0 å€¼ã€‚
"""

import os
import time
import pandas as pd
import numpy as np
import requests
import re
import gspread
import logging
import urllib3
from google.oauth2.service_account import Credentials
from google.auth import default
from datetime import datetime, timedelta, time as dt_time, date
from zoneinfo import ZoneInfo

# è‡ªå‹•å®‰è£ç¼ºå°‘çš„å¥—ä»¶
try:
    import twstock
except ImportError:
    os.system('pip install twstock gspread google-auth requests pandas zoneinfo --quiet')
    import twstock

# ==========================================
# 1. è¨­å®šèˆ‡å¸¸æ•¸
# ==========================================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

UNIT_LOT = 1000
# ğŸ”¥ é—œéµï¼šFinMind ä¸€æª”è‚¡ç¥¨è¦æŠ“ 4 æ¬¡ (Price, PER, PBR, DayTrading)
# 600 (ä¸Šé™) / 4 = 150ã€‚ä¿éšªèµ·è¦‹ï¼Œè¨­å®šæ¯å°æ™‚åªè·‘ 120 æª”ã€‚
MAX_STOCKS_PER_RUN = 120 

STATS_HEADERS = [
    'ä»£è™Ÿ', 'åç¨±', 'é€£çºŒå¤©æ•¸', 'è¿‘30æ—¥æ³¨æ„æ¬¡æ•¸', 'è¿‘10æ—¥æ³¨æ„æ¬¡æ•¸', 'æœ€è¿‘ä¸€æ¬¡æ—¥æœŸ',
    '30æ—¥ç‹€æ…‹ç¢¼', '10æ—¥ç‹€æ…‹ç¢¼', 'æœ€å¿«è™•ç½®å¤©æ•¸', 'è™•ç½®è§¸ç™¼åŸå› ', 'é¢¨éšªç­‰ç´š', 'è§¸ç™¼æ¢ä»¶',
    'ç›®å‰åƒ¹', 'è­¦æˆ’åƒ¹', 'å·®å¹…(%)', 'ç›®å‰é‡', 'è­¦æˆ’é‡', 'æˆäº¤å€¼(å„„)',
    'é€±è½‰ç‡(%)', 'PE', 'PB', 'ç•¶æ²–ä½”æ¯”(%)'
]

SHEET_NAME = "å°è‚¡æ³¨æ„è‚¡è³‡æ–™åº«_V33"
PARAM_SHEET_NAME = "å€‹è‚¡åƒæ•¸"

try: TW_TZ = ZoneInfo("Asia/Taipei")
except: TW_TZ = ZoneInfo("UTC")

TARGET_DATE = datetime.now(TW_TZ)
IS_AFTER_9PM = TARGET_DATE.hour >= 21

# ==========================================
# 2. API è¨­å®š
# ==========================================
FINMIND_API_URL = "https://api.finmindtrade.com/api/v4/data"
FINMIND_TOKEN = os.getenv('FinMind_1') or os.getenv('FinMind_2')

_FINMIND_CACHE = {}
API_CALL_COUNT = 0

# ============================
# 3. FinMind æ ¸å¿ƒ (å–ä»£ Yahoo)
# ============================
def finmind_get(dataset, data_id=None, start_date=None, end_date=None):
    global API_CALL_COUNT
    cache_key = (dataset, data_id, start_date, end_date)
    if cache_key in _FINMIND_CACHE: return _FINMIND_CACHE[cache_key].copy()

    params = { "dataset": dataset, "data_id": str(data_id), "start_date": start_date, "end_date": end_date }
    headers = {"User-Agent": "Mozilla/5.0"}
    if FINMIND_TOKEN: headers["Authorization"] = f"Bearer {FINMIND_TOKEN}"

    for _ in range(3):
        API_CALL_COUNT += 1
        try:
            time.sleep(1.2) # é¿å…å¤ªå¿«
            r = requests.get(FINMIND_API_URL, params=params, headers=headers, timeout=10, verify=False)
            if r.status_code == 200:
                j = r.json()
                df = pd.DataFrame(j.get("data", []))
                if not df.empty:
                    _FINMIND_CACHE[cache_key] = df
                return df
            elif r.status_code == 429:
                print("âš ï¸ FinMind 429 (Rate Limit).")
                return pd.DataFrame()
            time.sleep(2)
        except: time.sleep(1)
    return pd.DataFrame()

# [å…³é”®] æ”¹ç”¨ FinMind æŠ“æ­·å²è‚¡åƒ¹ (å–ä»£ yfinance)
def fetch_history_data_finmind(stock_id, days=120):
    end_str = TARGET_DATE.strftime("%Y-%m-%d")
    start_str = (TARGET_DATE - timedelta(days=days)).strftime("%Y-%m-%d")
    
    df = finmind_get("TaiwanStockPrice", data_id=stock_id, start_date=start_str, end_date=end_str)
    
    if df.empty: return pd.DataFrame()
    
    # æ¬„ä½æ¨™æº–åŒ–ä»¥ç¬¦åˆè¨ˆç®—é‚è¼¯
    df = df.rename(columns={
        "date": "Date", "open": "Open", "max": "High", "min": "Low", "close": "Close", "Trading_Volume": "Volume"
    })
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.set_index('Date').sort_index()
    
    # ç¢ºä¿æ•¸å€¼å‹æ…‹
    cols = ['Open', 'High', 'Low', 'Close', 'Volume']
    for c in cols: df[c] = pd.to_numeric(df[c], errors='coerce')
    
    return df

# [å…³é”®] æ”¹ç”¨ FinMind æŠ“ PE/PB
def fetch_fundamental_finmind(stock_id):
    date_str = TARGET_DATE.strftime("%Y-%m-%d")
    # å¾€å‰æŠ“å¹¾å¤©é¿å…å‡æ—¥æ²’è³‡æ–™
    start_str = (TARGET_DATE - timedelta(days=5)).strftime("%Y-%m-%d")
    
    res = {'pe': 0.0, 'pb': 0.0}
    
    # PE
    df_pe = finmind_get("TaiwanStockPER", data_id=stock_id, start_date=start_str, end_date=date_str)
    if not df_pe.empty:
        res['pe'] = float(df_pe.iloc[-1]['PER'])
        
    # PB
    df_pb = finmind_get("TaiwanStockPBR", data_id=stock_id, start_date=start_str, end_date=date_str)
    if not df_pb.empty:
        res['pb'] = float(df_pb.iloc[-1]['PBR'])
        
    return res

# [é—œéµ] æŠ“ç•¶æ²–
def get_daytrade_finmind(stock_id, date_str):
    # 9é»å‰ä¸æŠ“ï¼Œé™¤éå¼·åˆ¶
    if not IS_AFTER_9PM: return 0.0
    
    start = (datetime.strptime(date_str, "%Y-%m-%d") - timedelta(days=10)).strftime("%Y-%m-%d")
    d = finmind_get("TaiwanStockDayTrading", data_id=stock_id, start_date=start, end_date=date_str)
    p = finmind_get("TaiwanStockPrice", data_id=stock_id, start_date=start, end_date=date_str)
    
    if p.empty or d.empty: return 0.0
    
    try:
        m = pd.merge(p[['date','Trading_Volume']], d[['date','Volume']], on='date')
        if m.empty: return 0.0
        m = m.sort_values('date')
        last = m.iloc[-1]
        
        # åªè¦ç•¶å¤©çš„ä½”æ¯”
        if last['Trading_Volume'] > 0:
            return round((last['Volume'] / last['Trading_Volume']) * 100, 2)
    except: pass
    return 0.0

# ============================
# 4. è¨ˆç®—é‚è¼¯
# ============================
def calculate_risk(stock_id, hist, fund, est_days, dt_pct, shares=1):
    res = {
        'curr_price': 0, 'limit_price': 0, 'gap_pct': 999.0, 
        'curr_vol': 0, 'limit_vol': 0, 'turnover_val': 0, 'turnover_rate': 0,
        'pe': fund['pe'], 'pb': fund['pb'], 'day_trade_pct': dt_pct,
        'risk_level': 'ä½', 'trigger_msg': ''
    }
    
    if hist.empty: return res
    
    last = hist.iloc[-1]
    res['curr_price'] = last['Close']
    res['curr_vol'] = int(last['Volume'] / 1000)
    res['turnover_val'] = round((last['Close'] * last['Volume']) / 100000000, 2)
    
    if shares > 1:
        res['turnover_rate'] = round((last['Volume'] / shares) * 100, 2)
        
    # ç°¡æ˜“é¢¨éšªæ¨¡æ“¬ (é‚„åŸæ‚¨åŸæœ¬çš„é‚è¼¯)
    if est_days <= 1: res['risk_level'] = 'é«˜'
    elif est_days <= 2: res['risk_level'] = 'ä¸­'
    
    # è­¦æˆ’åƒ¹ (Ref * 1.32)
    if len(hist) >= 7:
        ref = hist.iloc[-7]['Close']
        res['limit_price'] = round(ref * 1.32, 2)
        if res['curr_price'] > 0:
            res['gap_pct'] = round(((res['limit_price'] - res['curr_price']) / res['curr_price']) * 100, 1)
            
    # è­¦æˆ’é‡ (60æ—¥å‡é‡ * 5)
    if len(hist) >= 60:
        avg_vol = hist.iloc[-60:]['Volume'].mean()
        res['limit_vol'] = int((avg_vol * 5) / 1000)
        
    return res

def get_ticker_suffix(market): return '.TWO' if 'ä¸Šæ«ƒ' in str(market) else '.TW'

# ============================
# 5. ä¸»ç¨‹å¼
# ============================
def connect_google_sheets():
    try:
        key = "/service_key.json" if os.path.exists("/service_key.json") else "service_key.json"
        if not os.path.exists(key): return None, None
        gc = gspread.service_account(filename=key)
        try: sh = gc.open(SHEET_NAME)
        except: sh = gc.create(SHEET_NAME)
        return sh, None
    except: return None, None

def get_or_create_ws(sh, title, headers=None):
    try: ws = sh.worksheet(title)
    except: 
        ws = sh.add_worksheet(title=title, rows="5000", cols="20")
        if headers: ws.append_row(headers)
    return ws

def main():
    print(f"ğŸš€ å•Ÿå‹• V116.22 æ•‘æ´ç‰ˆ | {TARGET_DATE}")
    
    sh, _ = connect_google_sheets()
    if not sh: return

    ws_stats = get_or_create_ws(sh, "è¿‘30æ—¥ç†±é–€çµ±è¨ˆ", headers=STATS_HEADERS)
    existing_data = ws_stats.get_all_records()
    
    today_str = TARGET_DATE.strftime("%Y-%m-%d")
    
    # å»ºç«‹ä»»å‹™æ¸…å–®
    target_list = []
    for row in existing_data:
        code = str(row.get('ä»£è™Ÿ'))
        last_date = str(row.get('æœ€è¿‘ä¸€æ¬¡æ—¥æœŸ'))
        # å¦‚æœæ—¥æœŸä¸æ˜¯ä»Šå¤©ï¼Œæˆ–è€…æ˜¯ä»Šå¤©ä½†æ•¸å€¼ç‚º0 (è¢«ä¹‹å‰çš„éŒ¯èª¤æ´—æ‰)ï¼Œå°±é‡æ–°æŠ“
        try: price = float(row.get('ç›®å‰åƒ¹', 0))
        except: price = 0
        
        if last_date != today_str or price == 0:
            target_list.append({'code': code, 'data': row, 'mode': 'FULL'})
        elif IS_AFTER_9PM:
            # 9é»å¾Œè£œç•¶æ²–
            try: dt = float(row.get('ç•¶æ²–ä½”æ¯”(%)', 0))
            except: dt = 0
            if dt == 0:
                target_list.append({'code': code, 'data': row, 'mode': 'DT'})

    print(f"ğŸ“‹ å¾…è™•ç†: {len(target_list)} æª” (æœ¬æ¬¡ä¸Šé™ {MAX_STOCKS_PER_RUN} æª”)")
    
    # è¼‰å…¥è‚¡æœ¬åƒæ•¸
    precise_db = {}
    try:
        ws_p = sh.worksheet(PARAM_SHEET_NAME)
        for r in ws_p.get_all_records():
            precise_db[str(r.get('ä»£è™Ÿ'))] = r.get('ç™¼è¡Œè‚¡æ•¸', 1)
    except: pass

    # åŸ·è¡Œ
    updates = []
    processed = 0
    
    for item in target_list:
        if processed >= MAX_STOCKS_PER_RUN:
            print("ğŸ›‘ é”åˆ°æœ¬å°æ™‚è™•ç†ä¸Šé™ï¼Œåœæ­¢ä¸¦å­˜æª”ã€‚")
            break
            
        code = item['code']
        old_data = item['data']
        mode = item['mode']
        
        print(f"   [{processed+1}] {code} ...", end="\r")
        
        # 1. æŠ“æ­·å²è‚¡åƒ¹ (FinMind)
        hist = fetch_history_data_finmind(code)
        
        # 2. æŠ“åŸºæœ¬é¢ (FinMind)
        fund = fetch_fundamental_finmind(code)
        
        # 3. æŠ“ç•¶æ²– (FinMind)
        dt_val = get_daytrade_finmind(code, today_str)
        
        # 4. è¨ˆç®—
        shares = 1
        try: shares = int(str(precise_db.get(code, 1)).replace(',',''))
        except: pass
        
        est_days = 99
        try: est_days = int(old_data.get('æœ€å¿«è™•ç½®å¤©æ•¸', 99))
        except: pass
        
        res = calculate_risk(code, hist, fund, est_days, dt_val, shares)
        
        # 5. æ›´æ–°
        new_row = old_data.copy()
        new_row['æœ€è¿‘ä¸€æ¬¡æ—¥æœŸ'] = today_str
        
        # å¦‚æœæŠ“ä¸åˆ°è³‡æ–™ (hist empty)ï¼Œä¿ç•™èˆŠå€¼æˆ–å¡«0ï¼Œé¿å…éŒ¯èª¤
        if not hist.empty:
            new_row['ç›®å‰åƒ¹'] = res['curr_price']
            new_row['è­¦æˆ’åƒ¹'] = res['limit_price']
            new_row['å·®å¹…(%)'] = res['gap_pct']
            new_row['ç›®å‰é‡'] = res['curr_vol']
            new_row['è­¦æˆ’é‡'] = res['limit_vol']
            new_row['æˆäº¤å€¼(å„„)'] = res['turnover_val']
            new_row['é€±è½‰ç‡(%)'] = res['turnover_rate']
            new_row['PE'] = res['pe']
            new_row['PB'] = res['pb']
            # ç•¶æ²–åªæœ‰åœ¨æœ‰å€¼çš„æ™‚å€™æ‰æ›´æ–°
            if res['day_trade_pct'] > 0:
                new_row['ç•¶æ²–ä½”æ¯”(%)'] = res['day_trade_pct']
        
        updates.append(new_row)
        processed += 1
        
    if updates:
        print(f"\nğŸ’¾ æ­£åœ¨å¯«å…¥ {len(updates)} ç­†è³‡æ–™...")
        update_map = {row['ä»£è™Ÿ']: row for row in updates}
        final_rows = []
        for row in existing_data:
            code = str(row.get('ä»£è™Ÿ'))
            target = update_map.get(code, row)
            final_rows.append([target.get(h, '') for h in STATS_HEADERS])
            
        ws_stats.clear()
        ws_stats.append_row(STATS_HEADERS, value_input_option='USER_ENTERED')
        ws_stats.append_rows(final_rows, value_input_option='USER_ENTERED')
        
    print(f"\nâœ… å®Œæˆã€‚APIä½¿ç”¨æ¬¡æ•¸: {API_CALL_COUNT}")

if __name__ == "__main__":
    main()
