# -*- coding: utf-8 -*-
import requests
import pandas as pd
import time
import yfinance as yf
import gspread
import logging
from google.auth import default
from google.colab import auth, userdata
from datetime import datetime, timedelta, date
from config import FINMIND_API_URL, PARAM_SHEET_NAME, SAFE_MARKET_OPEN_CHECK, SHEET_NAME
from utils import parse_clause_ids_strict, parse_jail_period, get_or_create_ws

# ==========================================
# æ¢å¾© yfinance éœéŸ³æ¨¡å¼ (é‚„åŸåŸå§‹é‚è¼¯)
# ==========================================
logger = logging.getLogger('yfinance')
logger.setLevel(logging.CRITICAL)
logger.disabled = True

# FinMind Token ç®¡ç†
try:
    token1 = userdata.get('FinMind_1')
    token2 = userdata.get('FinMind_2')
    FINMIND_TOKENS = [t for t in [token1, token2] if t]
except Exception as e:
    print(f"âš ï¸ ç„¡æ³•è®€å– Secrets: {e}")
    FINMIND_TOKENS = []

CURRENT_TOKEN_INDEX = 0
_FINMIND_CACHE = {}

def finmind_get(dataset, data_id=None, start_date=None, end_date=None):
    global CURRENT_TOKEN_INDEX
    cache_key = (dataset, data_id, start_date, end_date)
    if cache_key in _FINMIND_CACHE:
        return _FINMIND_CACHE[cache_key].copy()

    params = {"dataset": dataset}
    if data_id: params["data_id"] = str(data_id)
    if start_date: params["start_date"] = start_date
    if end_date: params["end_date"] = end_date
    if not FINMIND_TOKENS: return pd.DataFrame()

    for _ in range(4):
        headers = {"Authorization": f"Bearer {FINMIND_TOKENS[CURRENT_TOKEN_INDEX]}", "User-Agent": "Mozilla/5.0", "Connection": "close"}
        try:
            r = requests.get(FINMIND_API_URL, params=params, headers=headers, timeout=10)
            if r.status_code == 200:
                j = r.json()
                df = pd.DataFrame(j["data"]) if "data" in j else pd.DataFrame()
                if len(_FINMIND_CACHE) >= 2000: _FINMIND_CACHE.clear()
                _FINMIND_CACHE[cache_key] = df
                return df.copy()
            elif r.status_code != 200:
                print(f"   âš ï¸ Token {CURRENT_TOKEN_INDEX} ç•°å¸¸, åˆ‡æ›...")
                time.sleep(2)
                CURRENT_TOKEN_INDEX = (CURRENT_TOKEN_INDEX + 1) % len(FINMIND_TOKENS)
                continue
        except:
            time.sleep(1)
    return pd.DataFrame()

def connect_google_sheets():
    print("æ­£åœ¨é€²è¡Œ Google é©—è­‰...")
    try:
        auth.authenticate_user()
        creds, _ = default()
        gc = gspread.authorize(creds)
        try: sh = gc.open(SHEET_NAME)
        except: sh = gc.create(SHEET_NAME)
        return sh, None
    except: return None, None

def fetch_history_data(ticker_code):
    try:
        df = yf.Ticker(ticker_code).history(period="1y", auto_adjust=False)
        if df.empty: return pd.DataFrame()
        df.index = df.index.tz_localize(None)
        return df
    except: return pd.DataFrame()

def load_precise_db_from_sheet(sh):
    try:
        ws = sh.worksheet(PARAM_SHEET_NAME)
        data = ws.get_all_records()
        db = {}
        for row in data:
            code = str(row.get('ä»£è™Ÿ', '')).strip()
            if not code: continue
            try: shares = int(str(row.get('ç™¼è¡Œè‚¡æ•¸', 1)).replace(',', ''))
            except: shares = 1
            try: offset = float(row.get('é¡è‚¡æ¼²å¹…ä¿®æ­£', 0.0))
            except: offset = 0.0
            try: turn_avg = float(row.get('åŒé¡è‚¡å¹³å‡é€±è½‰', 5.0))
            except: turn_avg = 5.0
            try: purity = float(row.get('æˆäº¤é‡ç´”åº¦', 1.0))
            except: purity = 1.0
            market = str(row.get('å¸‚å ´', 'ä¸Šå¸‚')).strip()
            db[code] = {"market": market, "shares": shares, "sector_offset": offset, "sector_turn_avg": turn_avg, "vol_purity": purity}
        return db
    except: return {}

def fetch_stock_fundamental(stock_id, ticker_code, precise_db):
    market = 'ä¸Šå¸‚'; shares = 0
    if str(stock_id) in precise_db:
        db = precise_db[str(stock_id)]
        market = db['market']; shares = db['shares']
    data = {'shares': shares, 'market_type': market, 'pe': -1, 'pb': -1}
    try:
        t = yf.Ticker(ticker_code)
        if ".TWO" in ticker_code: data['market_type'] = 'ä¸Šæ«ƒ'
        if data['shares'] <= 1:
            s = t.fast_info.get('shares', None)
            if s: data['shares'] = int(s)
        data['pe'] = t.info.get('trailingPE', t.info.get('forwardPE', 0))
        data['pb'] = t.info.get('priceToBook', 0)
        if data['pe']: data['pe'] = round(data['pe'], 2)
        if data['pb']: data['pb'] = round(data['pb'], 2)
    except: pass
    return data

def get_daytrade_stats_finmind(stock_id, target_date_str):
    end_date = target_date_str
    start_date = (datetime.strptime(target_date_str, "%Y-%m-%d") - timedelta(days=15)).strftime("%Y-%m-%d")
    price_df = finmind_get("TaiwanStockPrice", data_id=stock_id, start_date=start_date, end_date=end_date)
    dt_df = finmind_get("TaiwanStockDayTrading", data_id=stock_id, start_date=start_date, end_date=end_date)
    if price_df.empty or dt_df.empty: return 0.0, 0.0
    try:
        merged = pd.merge(price_df[['date', 'Trading_Volume']], dt_df[['date', 'Volume']], on='date', how='inner')
        if merged.empty: return 0.0, 0.0
        merged['date'] = pd.to_datetime(merged['date'])
        merged = merged.sort_values('date')
        recent_6 = merged.tail(6)
        if len(recent_6) < 6: return 0.0, 0.0
        last_row = recent_6.iloc[-1]
        today_ratio = (last_row['Volume'] / last_row['Trading_Volume'] * 100.0) if last_row['Trading_Volume'] > 0 else 0.0
        sum_dt = recent_6['Volume'].sum()
        sum_total = recent_6['Trading_Volume'].sum()
        avg_6_ratio = (sum_dt / sum_total * 100.0) if sum_total > 0 else 0.0
        return round(today_ratio, 2), round(avg_6_ratio, 2)
    except: return 0.0, 0.0

def is_market_open_by_finmind(date_str):
    df = finmind_get("TaiwanStockPrice", data_id="2330", start_date=date_str, end_date=date_str)
    return not df.empty

def get_official_trading_calendar(days=60, target_date_obj=None):
    if not target_date_obj: target_date_obj = datetime.now()
    end_str = target_date_obj.strftime("%Y-%m-%d")
    start_str = (target_date_obj - timedelta(days=days*2)).strftime("%Y-%m-%d")
    print("ğŸ“… æ­£åœ¨ä¸‹è¼‰å®˜æ–¹äº¤æ˜“æ—¥æ›†...")
    df = finmind_get("TaiwanStockTradingDate", start_date=start_str, end_date=end_str)
    dates = []
    if not df.empty:
        df['date'] = pd.to_datetime(df['date']).dt.date
        dates = sorted(df['date'].tolist())
    else:
        curr = target_date_obj.date()
        while len(dates) < days:
            if curr.weekday() < 5: dates.append(curr)
            curr -= timedelta(days=1)
        dates = sorted(dates)
    
    today_date = target_date_obj.date()
    today_str = today_date.strftime("%Y-%m-%d")
    is_late_enough = target_date_obj.time() > SAFE_MARKET_OPEN_CHECK

    if dates and today_date > dates[-1] and today_date.weekday() < 5:
        if is_late_enough:
            print(f"âš ï¸ æ—¥æ›†ç¼ºæ¼ä»Šæ—¥ ({today_date})ï¼Œæ™‚é–“å·²é {SAFE_MARKET_OPEN_CHECK}ï¼Œé©—è­‰é–‹å¸‚ä¸­...")
            if is_market_open_by_finmind(today_str):
                print(f"âœ… é©—è­‰æˆåŠŸï¼Œè£œå…¥ä»Šæ—¥ã€‚")
                dates.append(today_date)
            else:
                print(f"â›” é©—è­‰å¤±æ•—ï¼Œä¸è£œå…¥ã€‚")
        else:
            print(f"â³ æ™‚é–“å°šæ—©ï¼Œæš«ä¸å¼·åˆ¶è£œå…¥ä»Šæ—¥ã€‚")
    return dates[-days:]

def get_daily_data(date_obj):
    date_str_nodash = date_obj.strftime("%Y%m%d")
    date_str = date_obj.strftime("%Y-%m-%d")
    rows = []
    error_count = 0
    print(f"ğŸ“¡ å˜—è©¦çˆ¬å–å®˜æ–¹å…¬å‘Š (æ—¥æœŸ: {date_str})...")
    # TWSE
    try:
        r = requests.get("https://www.twse.com.tw/rwd/zh/announcement/notice",
                         params={"startDate": date_str_nodash, "endDate": date_str_nodash, "response": "json"}, timeout=10)
        if r.status_code == 200:
            d = r.json()
            if 'data' in d:
                for i in d['data']:
                    code = str(i[1]).strip()
                    name = str(i[2]).strip()
                    if not (code.isdigit() and len(code) == 4): continue
                    raw_text = " ".join([str(x) for x in i])
                    ids = parse_clause_ids_strict(raw_text)
                    clause_str = "ã€".join([f"ç¬¬{k}æ¬¾" for k in sorted(ids)])
                    if not clause_str: clause_str = raw_text
                    rows.append({'æ—¥æœŸ': date_str, 'å¸‚å ´': 'TWSE', 'ä»£è™Ÿ': code, 'åç¨±': name, 'è§¸çŠ¯æ¢æ¬¾': clause_str})
        else: error_count += 1
    except: error_count += 1
    # TPEx
    try:
        roc_date = f"{date_obj.year-1911}/{date_obj.month:02d}/{date_obj.day:02d}"
        headers = {'User-Agent': 'Mozilla/5.0', 'Referer': 'https://www.tpex.org.tw/'}
        r = requests.post("https://www.tpex.org.tw/www/zh-tw/bulletin/attention", data={'date': roc_date, 'response': 'json'}, headers=headers, timeout=10)
        if r.status_code == 200:
            res = r.json()
            target = []
            if 'tables' in res:
                 for t in res['tables']: target.extend(t.get('data', []))
            elif 'data' in res: target = res['data']
            
            filtered_target = []
            if target:
                for row in target:
                    if len(row) > 5:
                        row_date = str(row[5]).strip()
                        if row_date == roc_date or row_date == date_str:
                            filtered_target.append(row)
            target = filtered_target

            for i in target:
                code = str(i[1]).strip()
                name = str(i[2]).strip()
                if not (code.isdigit() and len(code) == 4): continue
                raw_text = " ".join([str(x) for x in i])
                ids = parse_clause_ids_strict(raw_text)
                clause_str = "ã€".join([f"ç¬¬{k}æ¬¾" for k in sorted(ids)])
                if not clause_str: clause_str = raw_text
                rows.append({'æ—¥æœŸ': date_str, 'å¸‚å ´': 'TPEx', 'ä»£è™Ÿ': code, 'åç¨±': name, 'è§¸çŠ¯æ¢æ¬¾': clause_str})
        else: error_count += 1
    except: error_count += 1

    if error_count >= 2 and not rows: return None
    if rows: print(f"âœ… æˆåŠŸæŠ“åˆ° {len(rows)} æª”æ³¨æ„è‚¡ã€‚")
    else: print(f"âš ï¸ è©²æ—¥ ({date_str}) æŸ¥ç„¡è³‡æ–™ã€‚")
    return rows

def get_jail_map(start_date_obj, end_date_obj):
    print("ğŸ”’ æ­£åœ¨ä¸‹è¼‰è™•ç½®(Jail)åå–®...")
    jail_map = {}
    s_str = start_date_obj.strftime("%Y%m%d")
    e_str = end_date_obj.strftime("%Y%m%d")
    # TWSE
    try:
        url = "https://www.twse.com.tw/rwd/zh/announcement/punish"
        r = requests.get(url, params={"startDate": s_str, "endDate": e_str, "response": "json"}, timeout=10)
        j = r.json()
        def find_idx(fields, candidates):
            for c in candidates:
                if c in fields: return fields.index(c)
            return None
        if isinstance(j.get("tables"), list) and j["tables"]:
            t = j["tables"][0]
            fields = t.get("fields", [])
            data_rows = t.get("data", [])
            idx_code = find_idx(fields, ["è­‰åˆ¸ä»£è™Ÿ", "æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿ"]) or 2
            idx_period = find_idx(fields, ["è™•ç½®èµ·è¿„æ™‚é–“", "è™•ç½®èµ·è¨–æ™‚é–“"]) or 6
            for row in data_rows:
                try:
                    code = str(row[idx_code]).strip()
                    period_str = str(row[idx_period]).strip()
                    sd, ed = parse_jail_period(period_str)
                    if sd and ed: jail_map.setdefault(code, []).append((sd, ed))
                except: continue
        else:
            data_rows = j.get("data", [])
            for row in data_rows:
                try:
                    code = str(row[2]).strip() if len(row) > 2 else ""
                    period_str = str(row[6]).strip() if len(row) > 6 else ""
                    sd, ed = parse_jail_period(period_str)
                    if sd and ed: jail_map.setdefault(code, []).append((sd, ed))
                except: continue
    except Exception as e: print(f"âš ï¸ TWSE è™•ç½®å¤±æ•—: {e}")
    # TPEx
    try:
        url = "https://www.tpex.org.tw/openapi/v1/tpex_disposal_information"
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            data = r.json()
            for item in data:
                try:
                    code = str(item.get("SecuritiesCompanyCode", "")).strip()
                    if not code.isdigit() or len(code) != 4: continue
                    period = str(item.get("DispositionPeriod", "")).strip()
                    sd, ed = parse_jail_period(period)
                    if not sd or not ed: continue
                    if ed >= start_date_obj and sd <= end_date_obj:
                        jail_map.setdefault(code, []).append((sd, ed))
                except: continue
    except Exception as e: print(f"âš ï¸ TPEx è™•ç½®å¤±æ•—: {e}")
    for k in jail_map: jail_map[k] = sorted(jail_map[k], key=lambda x: x[0])
    return jail_map

def update_market_monitoring_log(sh, target_date_obj):
    print("ğŸ“Š æª¢æŸ¥ä¸¦æ›´æ–°ã€Œå¤§ç›¤æ•¸æ“šç›£æ§ã€...")
    HEADERS = ['æ—¥æœŸ', 'ä»£è™Ÿ', 'åç¨±', 'æ”¶ç›¤åƒ¹', 'æ¼²è·Œå¹…(%)', 'æˆäº¤é‡‘é¡(å„„)']
    ws_market = get_or_create_ws(sh, "å¤§ç›¤æ•¸æ“šç›£æ§", headers=HEADERS, cols=10)
    def norm_date(s):
        s = str(s).strip()
        if not s: return ""
        try: return pd.to_datetime(s, errors='coerce').strftime("%Y-%m-%d")
        except: return s
    key_to_row = {}
    try:
        all_vals = ws_market.get_all_values()
        for r_idx, row in enumerate(all_vals[1:], start=2):
            if len(row) >= 2:
                d_str = norm_date(row[0])
                c_str = str(row[1]).strip()
                if d_str and c_str: key_to_row[f"{d_str}_{c_str}"] = r_idx
    except: pass
    existing_keys = set(key_to_row.keys())
    try:
        targets = [{'fin_id': 'TAIEX', 'code': '^TWII', 'name': 'åŠ æ¬ŠæŒ‡æ•¸'}, {'fin_id': 'TPEx', 'code': '^TWOII', 'name': 'æ«ƒè²·æŒ‡æ•¸'}]
        start_date_str = (target_date_obj - timedelta(days=45)).strftime("%Y-%m-%d")
        dfs = {}
        for t in targets:
            df = finmind_get("TaiwanStockPrice", data_id=t['fin_id'], start_date=start_date_str)
            if not df.empty:
                if 'date' in df.columns:
                    df['date'] = pd.to_datetime(df['date'])
                    df.set_index('date', inplace=True)
                    df.index = df.index.tz_localize(None)
                if 'close' in df.columns:
                    df['Close'] = df['close'].astype(float)
                    df['Pct'] = df['Close'].pct_change() * 100
                if 'Turnover' in df.columns: df['Volume'] = df['Turnover'].astype(float)
                elif 'Trading_money' in df.columns: df['Volume'] = df['Trading_money'].astype(float)
                else: df['Volume'] = 0.0
                dfs[t['code']] = df
        new_rows = []
        today_str = target_date_obj.strftime("%Y-%m-%d")
        all_dates = set()
        for df in dfs.values(): all_dates.update(df.index.strftime("%Y-%m-%d").tolist())
        for d in sorted(all_dates):
            for t in targets:
                code = t['code']
                df = dfs.get(code)
                if df is None or d not in df.index.strftime("%Y-%m-%d"): continue
                try: row = df.loc[d]
                except: row = df[df.index.strftime("%Y-%m-%d") == d].iloc[0]
                close_val = row.get('Close', 0)
                if pd.isna(close_val): continue
                close = round(float(close_val), 2)
                pct = round(float(row.get('Pct', 0) or 0), 2)
                vol_raw = float(row.get('Volume', 0) or 0)
                vol_billion = round(vol_raw / 100000000, 2)
                row_data = [d, code, t['name'], close, pct, vol_billion]
                comp_key = f"{d}_{code}"
                if d == today_str and target_date_obj.time() < SAFE_MARKET_OPEN_CHECK: continue
                if d == today_str and comp_key in key_to_row and target_date_obj.time() >= SAFE_MARKET_OPEN_CHECK:
                    r_num = key_to_row[comp_key]
                    try: ws_market.update(values=[row_data], range_name=f'A{r_num}:F{r_num}', value_input_option="USER_ENTERED")
                    except: pass
                    continue
                if comp_key in existing_keys: continue
                if close > 0: new_rows.append(row_data)
        if new_rows:
            ws_market.append_rows(new_rows, value_input_option="USER_ENTERED")
            print(f"   âœ… å·²è£œå…¥ {len(new_rows)} ç­†å¤§ç›¤æ•¸æ“šã€‚")
        else: print("   âœ… å¤§ç›¤æ•¸æ“šå·²æ˜¯æœ€æ–°ã€‚")
    except Exception as e: print(f"   âŒ å¤§ç›¤æ›´æ–°å¤±æ•—: {e}")
