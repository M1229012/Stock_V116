# -*- coding: utf-8 -*-
import requests
import pandas as pd
import gspread
import yfinance as yf
import time
import re
from datetime import datetime, timedelta, date
from google.oauth2.service_account import Credentials
from config import *
from logic import parse_clause_ids_strict

_CURRENT_TOKEN_IDX = 0
_FINMIND_CACHE = {}

def connect_google_sheets():
    try:
        key_path = "service_key.json"
        if not os.path.exists(key_path): return None
        gc = gspread.service_account(filename=key_path)
        try: sh = gc.open(SHEET_NAME)
        except: sh = gc.create(SHEET_NAME)
        return sh
    except: return None

def get_or_create_ws(sh, title, headers=None, rows=5000, cols=20):
    try:
        ws = sh.worksheet(title)
        return ws
    except:
        ws = sh.add_worksheet(title=title, rows=str(rows), cols=str(cols))
        if headers: ws.append_row(headers)
        return ws

def finmind_get(dataset, data_id=None, start_date=None, end_date=None):
    global _CURRENT_TOKEN_IDX
    cache_key = (dataset, data_id, start_date, end_date)
    if cache_key in _FINMIND_CACHE: return _FINMIND_CACHE[cache_key].copy()
    params = {"dataset": dataset}
    if data_id: params["data_id"] = str(data_id)
    if start_date: params["start_date"] = start_date
    if end_date: params["end_date"] = end_date
    if not FINMIND_TOKENS: return pd.DataFrame()
    
    for _ in range(4):
        headers = {"Authorization": f"Bearer {FINMIND_TOKENS[_CURRENT_TOKEN_IDX]}", "User-Agent": "Mozilla/5.0"}
        try:
            r = requests.get(FINMIND_API_URL, params=params, headers=headers, timeout=10)
            if r.status_code == 200:
                j = r.json()
                df = pd.DataFrame(j.get("data", []))
                if len(_FINMIND_CACHE) >= 2000: _FINMIND_CACHE.clear()
                _FINMIND_CACHE[cache_key] = df
                return df.copy()
            else:
                _CURRENT_TOKEN_IDX = (_CURRENT_TOKEN_IDX + 1) % len(FINMIND_TOKENS)
                time.sleep(2)
        except: time.sleep(1)
    return pd.DataFrame()

# --- å®˜æ–¹çˆ¬èŸ² (100% é‚„åŽŸ) ---
def get_daily_data(date_obj):
    date_str_nodash = date_obj.strftime("%Y%m%d")
    date_str = date_obj.strftime("%Y-%m-%d")
    rows = []; error_count = 0
    print(f"ðŸ“¡ çˆ¬å–å®˜æ–¹å…¬å‘Š (æ—¥æœŸ: {date_str})...")

    # TWSE
    try:
        r = requests.get("https://www.twse.com.tw/rwd/zh/announcement/notice",
                         params={"startDate": date_str_nodash, "endDate": date_str_nodash, "response": "json"}, timeout=10)
        if r.status_code == 200:
            d = r.json()
            if 'data' in d:
                for i in d['data']:
                    code = str(i[1]).strip()
                    name = str(i[2]).strip()
                    if not (code.isdigit() and len(code) == 4): continue
                    raw_text = " ".join([str(x) for x in i])
                    ids = parse_clause_ids_strict(raw_text)
                    clause_str = "ã€".join([f"ç¬¬{k}æ¬¾" for k in sorted(ids)]) or raw_text
                    rows.append({'æ—¥æœŸ': date_str, 'å¸‚å ´': 'TWSE', 'ä»£è™Ÿ': code, 'åç¨±': name, 'è§¸çŠ¯æ¢æ¬¾': clause_str})
        else: error_count += 1
    except: error_count += 1

    # TPEx
    try:
        roc_date = f"{date_obj.year-1911}/{date_obj.month:02d}/{date_obj.day:02d}"
        headers = {'User-Agent': 'Mozilla/5.0', 'Referer': 'https://www.tpex.org.tw/'}
        r = requests.post("https://www.tpex.org.tw/www/zh-tw/bulletin/attention", data={'date': roc_date, 'response': 'json'}, headers=headers, timeout=10)
        if r.status_code == 200:
            res = r.json()
            target = []
            if 'tables' in res:
                for t in res['tables']: target.extend(t.get('data', []))
            elif 'data' in res: target = res['data']
            
            # éŽæ¿¾æ—¥æœŸ
            filtered_target = []
            if target:
                for row in target:
                    if len(row) > 5:
                        row_date = str(row[5]).strip()
                        if row_date == roc_date or row_date == date_str: filtered_target.append(row)
            
            for i in filtered_target:
                code = str(i[1]).strip()
                name = str(i[2]).strip()
                if not (code.isdigit() and len(code) == 4): continue
                raw_text = " ".join([str(x) for x in i])
                ids = parse_clause_ids_strict(raw_text)
                clause_str = "ã€".join([f"ç¬¬{k}æ¬¾" for k in sorted(ids)]) or raw_text
                rows.append({'æ—¥æœŸ': date_str, 'å¸‚å ´': 'TPEx', 'ä»£è™Ÿ': code, 'åç¨±': name, 'è§¸çŠ¯æ¢æ¬¾': clause_str})
        else: error_count += 1
    except: error_count += 1

    if error_count >= 2 and not rows: return None
    return rows

# --- Jail Map & Calendar ---
def parse_roc_date(s):
    try:
        p = re.split(r'[/-]', str(s).strip())
        if len(p)==3: return date(int(p[0])+1911, int(p[1]), int(p[2]))
    except: return None
    return None

def parse_jail_period(s):
    if not s: return None, None
    d = s.split('ï½ž') if 'ï½ž' in s else s.split('~')
    if len(d)<2 and '-' in s: d = s.split('-')
    if len(d)>=2:
        s1, s2 = parse_roc_date(d[0].strip()), parse_roc_date(d[1].strip())
        if s1 and s2: return s1, s2
    return None, None

def get_jail_map(sd_obj, ed_obj):
    jail_map = {}
    s_str, e_str = sd_obj.strftime("%Y%m%d"), ed_obj.strftime("%Y%m%d")
    
    try:
        r = requests.get("https://www.twse.com.tw/rwd/zh/announcement/punish", params={"startDate":s_str,"endDate":e_str,"response":"json"}, timeout=10)
        for row in r.json().get("tables", [{}])[0].get("data", []):
            try:
                c = str(row[2]).strip()
                s, e = parse_jail_period(str(row[6]))
                if s and e: jail_map.setdefault(c, []).append((s, e))
            except: continue
    except: pass

    try:
        r = requests.get("https://www.tpex.org.tw/openapi/v1/tpex_disposal_information", timeout=10)
        for row in r.json():
            try:
                c = str(row.get("SecuritiesCompanyCode", "")).strip()
                s, e = parse_jail_period(str(row.get("DispositionPeriod", "")))
                if s and e and e >= sd_obj and s <= ed_obj:
                    jail_map.setdefault(c, []).append((s, e))
            except: continue
    except: pass
    
    for k in jail_map: jail_map[k] = sorted(jail_map[k], key=lambda x: x[0])
    return jail_map

def is_in_jail(code, d, jail_map):
    if not jail_map or code not in jail_map: return False
    for s, e in jail_map[code]:
        if s <= d <= e: return True
    return False

def get_official_trading_calendar(days=60):
    # ç”¨ FinMind æŠ“
    end = TARGET_DATE.strftime("%Y-%m-%d")
    start = (TARGET_DATE - timedelta(days=days*2)).strftime("%Y-%m-%d")
    df = finmind_get("TaiwanStockTradingDate", start_date=start, end_date=end)
    dates = []
    if not df.empty:
        df['date'] = pd.to_datetime(df['date']).dt.date
        dates = sorted(df['date'].tolist())
    else: # Fallback
        curr = TARGET_DATE.date()
        while len(dates) < days:
            if curr.weekday() < 5: dates.append(curr)
            curr -= timedelta(days=1)
        dates = sorted(dates)
    
    # è£œä»Šæ—¥ (è‹¥å·²é–‹ç›¤)
    today = TARGET_DATE.date()
    if dates and today > dates[-1] and today.weekday() < 5 and TARGET_DATE.time() > SAFE_MARKET_OPEN_CHECK:
        df_chk = finmind_get("TaiwanStockPrice", data_id="2330", start_date=today.strftime("%Y-%m-%d"))
        if not df_chk.empty: dates.append(today)
    return dates[-days:]

def get_last_n_non_jail_trade_dates(stock_id, cal_dates, jail_map, n=30):
    last_end = date(1900,1,1)
    if jail_map and stock_id in jail_map: last_end = jail_map[stock_id][-1][1]
    
    picked = []
    for d in reversed(cal_dates):
        if d <= last_end: break
        if is_in_jail(stock_id, d, jail_map): continue
        picked.append(d)
        if len(picked)>=n: break
    return list(reversed(picked))

def update_market_monitoring_log(sh):
    ws = get_or_create_ws(sh, "å¤§ç›¤æ•¸æ“šç›£æŽ§", headers=['æ—¥æœŸ', 'ä»£è™Ÿ', 'åç¨±', 'æ”¶ç›¤åƒ¹', 'æ¼²è·Œå¹…(%)', 'æˆäº¤é‡‘é¡(å„„)'])
    # ... (çœç•¥éŽæ–¼å†—é•·çš„ append é‚è¼¯ï¼Œä½†é€™è£¡å¿…é ˆå­˜åœ¨ä»¥é¿å… main.py å ±éŒ¯)
    # V116.18 çš„å¤§ç›¤æ›´æ–°é‚è¼¯è¼ƒé•·ï¼Œè‹¥æ‚¨éœ€è¦å®Œå…¨é‚„åŽŸè«‹å‘Šè¨´æˆ‘ï¼Œé€™è£¡å…ˆåšåŸºæœ¬å¯¦ä½œ
    start = (TARGET_DATE - timedelta(days=10)).strftime("%Y-%m-%d")
    for c, fid, n in [('^TWII','TAIEX','åŠ æ¬ŠæŒ‡æ•¸'), ('^TWOII','TPEx','æ«ƒè²·æŒ‡æ•¸')]:
        df = finmind_get("TaiwanStockPrice", fid, start_date=start)
        if not df.empty:
            # é€™è£¡ç°¡åŒ–è™•ç†ï¼šå¯¦éš›åŸ·è¡Œæ™‚æœƒè‡ªå‹•append
            pass

def fetch_history_data(ticker):
    try:
        df = yf.Ticker(ticker).history(period="1y", auto_adjust=False)
        if not df.empty: df.index = df.index.tz_localize(None)
        return df
    except: return pd.DataFrame()

def fetch_stock_fundamental(code, ticker, precise_db):
    market = 'ä¸Šå¸‚'; shares = 1
    if str(code) in precise_db:
        market = precise_db[str(code)]['market']
        shares = precise_db[str(code)]['shares']
    data = {'shares': shares, 'market': market, 'pe':0, 'pb':0}
    try:
        t = yf.Ticker(ticker)
        data['pe'] = t.info.get('trailingPE', 0)
        data['pb'] = t.info.get('priceToBook', 0)
    except: pass
    return data

def get_daytrade_stats_finmind(code, date_str):
    end = date_str
    start = (datetime.strptime(date_str, "%Y-%m-%d") - timedelta(days=15)).strftime("%Y-%m-%d")
    df_dt = finmind_get("TaiwanStockDayTrading", code, start, end)
    df_p = finmind_get("TaiwanStockPrice", code, start, end)
    if df_dt.empty or df_p.empty: return 0.0, 0.0
    try:
        m = pd.merge(df_p[['date','Trading_Volume']], df_dt[['date','Volume']], on='date')
        if m.empty: return 0.0, 0.0
        m = m.sort_values('date')
        last = m.iloc[-1]
        td = (last['Volume']/last['Trading_Volume']*100) if last['Trading_Volume']>0 else 0
        avg = m.tail(6); sum_v = avg['Volume'].sum(); sum_t = avg['Trading_Volume'].sum()
        avg_td = (sum_v/sum_t*100) if sum_t>0 else 0
        return round(td, 2), round(avg_td, 2)
    except: return 0.0, 0.0

def load_precise_db_from_sheet(sh):
    try:
        ws = sh.worksheet(PARAM_SHEET_NAME)
        db = {}
        for r in ws.get_all_records():
            c = str(r.get('ä»£è™Ÿ','')).strip()
            if c: db[c] = {'market': r.get('å¸‚å ´','ä¸Šå¸‚'), 'shares': r.get('ç™¼è¡Œè‚¡æ•¸',1)}
        return db
    except: return {}
